{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b646d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sb\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56cc3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real_1</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real_10</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real_100</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real_101</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real_102</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  images_id label\n",
       "0    real_1  real\n",
       "1   real_10  real\n",
       "2  real_100  real\n",
       "3  real_101  real\n",
       "4  real_102  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"deepfake/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af34e643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 128, 128, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width=128, 128\n",
    "X=np.empty((data.shape[0], height, width, 3))\n",
    "for i in range(data.shape[0]):\n",
    "    img=load_img(\"deepfake/{}/{}.jpg\".format(data.loc[i, 'label'], \\\n",
    "                  data.loc[i, 'images_id']), target_size=(height, width))\n",
    "    X[i]=img_to_array(img)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd3b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def changeLabels(x):\n",
    "    return labels[x]\n",
    "\n",
    "labels=data.label.unique()\n",
    "labels={labels[i]:i for i in range(labels.size)}\n",
    "y=data.label.apply(changeLabels)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a80aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74efc1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=to_categorical(y, len(labels))\n",
    "y=y.astype(int)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40752aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3712f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1031, 128, 128, 3), (1031, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35928725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e42aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(height, width, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "999da982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "26/26 [==============================] - 9s 46ms/step - loss: 3.0722 - accuracy: 0.5570 - val_loss: 0.7003 - val_accuracy: 0.5894\n",
      "Epoch 2/8\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6459 - accuracy: 0.6663 - val_loss: 0.4339 - val_accuracy: 0.8502\n",
      "Epoch 3/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4437 - accuracy: 0.7755 - val_loss: 0.2439 - val_accuracy: 0.9372\n",
      "Epoch 4/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2764 - accuracy: 0.8896 - val_loss: 0.1521 - val_accuracy: 0.9614\n",
      "Epoch 5/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.1689 - accuracy: 0.9381 - val_loss: 0.1108 - val_accuracy: 0.9710\n",
      "Epoch 6/8\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.1465 - accuracy: 0.9357 - val_loss: 0.0964 - val_accuracy: 0.9710\n",
      "Epoch 7/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.1038 - accuracy: 0.9612 - val_loss: 0.0914 - val_accuracy: 0.9807\n",
      "Epoch 8/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0869 - accuracy: 0.9672 - val_loss: 0.1095 - val_accuracy: 0.9710\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 42, 42, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                18496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,130\n",
      "Trainable params: 48,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs=8\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "stats=model.fit(X_train, y_train, epochs=epochs, validation_split=0.2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059cbed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1843 - accuracy: 0.9393 - val_loss: 0.1070 - val_accuracy: 0.9807\n",
      "Epoch 2/8\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0671 - accuracy: 0.9733 - val_loss: 0.0781 - val_accuracy: 0.9903\n",
      "Epoch 3/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0697 - accuracy: 0.9842 - val_loss: 0.0570 - val_accuracy: 0.9807\n",
      "Epoch 4/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0350 - val_accuracy: 0.9952\n",
      "Epoch 5/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0536 - val_accuracy: 0.9807\n",
      "Epoch 6/8\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.0247 - accuracy: 0.9951 - val_loss: 0.0236 - val_accuracy: 0.9855\n",
      "Epoch 7/8\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0553 - val_accuracy: 0.9903\n",
      "Epoch 8/8\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.0732 - val_accuracy: 0.9855\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 42, 42, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                18496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,130\n",
      "Trainable params: 48,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs=8\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "stats=model.fit(X_train, y_train, epochs=epochs, validation_split=0.2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85260195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1315 - accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "_, accuracy=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c96b8cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "classes_predicted=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3201185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25f9f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "14450538",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.image_utils.load_img(\"onedrive/desktop/GIF-generator-emmawatson1-mov-image.jpg\",target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "5a41a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.image_utils.img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b443fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "edd541b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['real','fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "61f35fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionclass=class_names[prediction.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "56bda2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2613918e-05, 9.9997735e-01], dtype=float32)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "21b68691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "71b8a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake\n"
     ]
    }
   ],
   "source": [
    "print(predictionclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9616fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('imagesdeepfake.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17861b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd114f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
