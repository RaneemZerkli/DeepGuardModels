{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2400ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ed5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('arabicdeepfakedetection5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfea6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Inputs</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34977</td>\n",
       "      <td>برنامج Essentials Pro 9. 0. 2. 1. 6 Portable ي...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46463</td>\n",
       "      <td>عرب بت - أعلنت اللجنة المنظمة لمهرجان التسوق ا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36231</td>\n",
       "      <td>وكانت وزارة الاستثمار قد رفعت أسعار تلك الخدما...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>قال وزير الخارجية البريطاني ، ويليام هيج ، الي...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42859</td>\n",
       "      <td>حجز تشيلسي فرصة التتويج بلقب دوري أبطال أوروبا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87447</th>\n",
       "      <td>99995</td>\n",
       "      <td>رائع وموقعه مميز . موقع الفندق بالقرب من الخور...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87448</th>\n",
       "      <td>99996</td>\n",
       "      <td>رحلة مميزة بالقرب من الحرم . تعامل الموظفين كا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87449</th>\n",
       "      <td>99997</td>\n",
       "      <td>حجز لثلاث اشخاص . تسجيل الدخول للفندق و تسجيل ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87450</th>\n",
       "      <td>99998</td>\n",
       "      <td>مخيب للأمل. . تسجيل الدخول استغرق اكثر من ساعتين</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87451</th>\n",
       "      <td>99999</td>\n",
       "      <td>فندق رائع لمن يبحث الاسترخاء والمتعة . كل شئ م...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Inputs  Label\n",
       "0           34977  برنامج Essentials Pro 9. 0. 2. 1. 6 Portable ي...      0\n",
       "1           46463  عرب بت - أعلنت اللجنة المنظمة لمهرجان التسوق ا...      0\n",
       "2           36231  وكانت وزارة الاستثمار قد رفعت أسعار تلك الخدما...      0\n",
       "3              71  قال وزير الخارجية البريطاني ، ويليام هيج ، الي...      0\n",
       "4           42859  حجز تشيلسي فرصة التتويج بلقب دوري أبطال أوروبا...      0\n",
       "...           ...                                                ...    ...\n",
       "87447       99995  رائع وموقعه مميز . موقع الفندق بالقرب من الخور...      1\n",
       "87448       99996  رحلة مميزة بالقرب من الحرم . تعامل الموظفين كا...      1\n",
       "87449       99997  حجز لثلاث اشخاص . تسجيل الدخول للفندق و تسجيل ...      1\n",
       "87450       99998   مخيب للأمل. . تسجيل الدخول استغرق اكثر من ساعتين      1\n",
       "87451       99999  فندق رائع لمن يبحث الاسترخاء والمتعة . كل شئ م...      1\n",
       "\n",
       "[87452 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc67f67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43726\n",
       "1    43726\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900a0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text = df['Inputs']\n",
    "label = df['Label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(text, label, test_size=0.25, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e46be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at akhooli/gpt2-small-arabic were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"akhooli/gpt2-small-arabic\")\n",
    "\n",
    "# Initialize the GPT-2 model for Arabic\n",
    "\n",
    "gpt2_model = AutoModel.from_pretrained(\"akhooli/gpt2-small-arabic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7466b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(tokenizer, texts):\n",
    "  \"\"\"Tokenizes a list of text strings using the given BERT tokenizer.\n",
    "\n",
    "  Args:\n",
    "    tokenizer: A BERT tokenizer.\n",
    "    texts: A list of text strings.\n",
    "\n",
    "  Returns:\n",
    "    A list of tokenized sentences, where each sentence is a list of token IDs.\n",
    "  \"\"\"\n",
    "\n",
    "  tokenized_texts = []\n",
    "  for text in texts:\n",
    "    # Fix the error by removing the `return_tensors='pt'` argument.\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, max_length=128)['input_ids']\n",
    "    tokenized_texts.append(tokens)\n",
    "\n",
    "  return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3dd322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6755f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =tokenize_data(tokenizer, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74cf58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 =tokenize_data(tokenizer, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f874bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "x_train=pad_sequences(x)\n",
    "x_val=pad_sequences(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a943d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "# Create an embedding layer using GPT-2's embedding weights\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=gpt2_model.config.vocab_size,\n",
    "    output_dim=gpt2_model.config.hidden_size,\n",
    "    weights=[gpt2_model.get_input_embeddings().weight.detach()],\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "579b1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile your Keras model with the pre-built GPT-2 embedding layer\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)  # Use the pre-built embedding layer\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))  # Bidirectional LSTM layer with 128 units\n",
    "model.add(Dropout(0.2))  # Apply dropout for regularization\n",
    "model.add(Bidirectional(LSTM(64)))  # Bidirectional LSTM layer with 64 units\n",
    "model.add(Dropout(0.2))  # Apply dropout for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train your model using X_train and y_train\n",
    "# Evaluate your model on X_val and y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95238129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f1cc447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 8s 56ms/step - loss: 0.2373 - accuracy: 0.8916\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0391 - accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0275 - accuracy: 0.9925\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0425 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0255 - accuracy: 0.9925\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0245 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0158 - accuracy: 0.9956\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0108 - accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c19e90a440>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10,steps_per_epoch=100,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c43cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 23ms/step - loss: 0.0191 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01909259334206581, 0.994785726070404]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val,y_val,steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0192126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e161d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted class: human written [[0.58353674]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text=''\n",
    "\n",
    "\n",
    "\n",
    "text_p = [text]\n",
    "x2 = tokenize_data(gpt2_tokenizer, text_p)\n",
    "\n",
    "# Make a prediction\n",
    "prediction_input = np.array(x2).reshape(-1)\n",
    "prediction_input=pad_sequences([prediction_input],128)\n",
    "\n",
    "\n",
    "output = model.predict(prediction_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if output > 0.5:\n",
    "    predicted_class = 'human written'\n",
    "else:\n",
    "    predicted_class = 'machine generated'\n",
    "\n",
    "# Print the predicted class\n",
    "print('Predicted class:', predicted_class,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef53d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aragpt2deepfaketextdetection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a289df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile your Keras model with the pre-built GPT-2 embedding layer\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)  # Use the pre-built embedding layer\n",
    "\n",
    "model.add(LSTM(12))  # Bidirectional LSTM layer with 64 units\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train your model using X_train and y_train\n",
    "# Evaluate your model on X_val and y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afca2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1456b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 11s 41ms/step - loss: 0.2777 - accuracy: 0.9041\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0553 - accuracy: 0.9872\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0409 - accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0340 - accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.0322 - accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0283 - accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0214 - accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 0.0308 - accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.0167 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.0181 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4b69b850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10,steps_per_epoch=100,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e476733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 12ms/step - loss: 0.0255 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02554127760231495, 0.9933220744132996]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val,y_val,steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41185a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aragpt2deepfaketextdetectionLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8ffdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
