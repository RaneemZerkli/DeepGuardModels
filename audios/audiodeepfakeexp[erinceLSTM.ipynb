{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "456d087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"for-rerecorded/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79340cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ebeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, mfcc=True, chroma=True, mel=True):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    features = []\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
    "        features.extend(mfccs)\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate), axis=1)\n",
    "        features.extend(chroma)\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate), axis=1)\n",
    "        features.extend(mel)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31225411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013cd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data_path, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder in enumerate(labels):\n",
    "        for filename in os.listdir(os.path.join(data_path, folder)):\n",
    "            file_path = os.path.join(data_path, folder, filename)\n",
    "            features = extract_features(file_path)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d261d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"fake\", \"real\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2fb5c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_dataset(data_path, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "30c284f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y)\n",
    "y = lb.transform(y)\n",
    "y = y.ravel()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bfbfcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6de7ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b424e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "65541f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9322fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4690fb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6decf8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1=\"for-rerecorded/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dea67526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = preprocess_dataset(data_path1, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "95937d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb1 = preprocessing.LabelBinarizer()\n",
    "lb1.fit(y1)\n",
    "y1 = lb.transform(y1)\n",
    "y1 = y1.ravel()\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "03e9fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ee3be799",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "01f429d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-256.103912</td>\n",
       "      <td>98.469414</td>\n",
       "      <td>22.013477</td>\n",
       "      <td>52.473427</td>\n",
       "      <td>-19.976601</td>\n",
       "      <td>12.298381</td>\n",
       "      <td>-13.486473</td>\n",
       "      <td>-21.096678</td>\n",
       "      <td>-8.685554</td>\n",
       "      <td>-14.394847</td>\n",
       "      <td>...</td>\n",
       "      <td>5.152135e-06</td>\n",
       "      <td>4.850130e-06</td>\n",
       "      <td>4.598218e-06</td>\n",
       "      <td>4.396695e-06</td>\n",
       "      <td>4.228468e-06</td>\n",
       "      <td>4.089994e-06</td>\n",
       "      <td>3.981520e-06</td>\n",
       "      <td>3.896523e-06</td>\n",
       "      <td>3.837688e-06</td>\n",
       "      <td>3.799962e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-300.186493</td>\n",
       "      <td>85.507095</td>\n",
       "      <td>20.787426</td>\n",
       "      <td>23.039135</td>\n",
       "      <td>2.667248</td>\n",
       "      <td>13.296325</td>\n",
       "      <td>-2.531562</td>\n",
       "      <td>1.466273</td>\n",
       "      <td>-0.258310</td>\n",
       "      <td>-9.347284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021982e-05</td>\n",
       "      <td>9.616067e-06</td>\n",
       "      <td>9.112850e-06</td>\n",
       "      <td>8.710424e-06</td>\n",
       "      <td>8.375203e-06</td>\n",
       "      <td>8.097788e-06</td>\n",
       "      <td>7.881747e-06</td>\n",
       "      <td>7.711950e-06</td>\n",
       "      <td>7.595052e-06</td>\n",
       "      <td>7.520370e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-157.332275</td>\n",
       "      <td>127.011574</td>\n",
       "      <td>-5.880052</td>\n",
       "      <td>43.091164</td>\n",
       "      <td>-18.972185</td>\n",
       "      <td>23.088911</td>\n",
       "      <td>-13.768730</td>\n",
       "      <td>-11.887770</td>\n",
       "      <td>-1.636095</td>\n",
       "      <td>-30.187855</td>\n",
       "      <td>...</td>\n",
       "      <td>3.442305e-06</td>\n",
       "      <td>3.239278e-06</td>\n",
       "      <td>3.070470e-06</td>\n",
       "      <td>2.935717e-06</td>\n",
       "      <td>2.823577e-06</td>\n",
       "      <td>2.731393e-06</td>\n",
       "      <td>2.658706e-06</td>\n",
       "      <td>2.602187e-06</td>\n",
       "      <td>2.563323e-06</td>\n",
       "      <td>2.538142e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-276.085114</td>\n",
       "      <td>133.718170</td>\n",
       "      <td>27.578678</td>\n",
       "      <td>36.164024</td>\n",
       "      <td>1.329927</td>\n",
       "      <td>-0.267277</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>-10.962516</td>\n",
       "      <td>-5.820240</td>\n",
       "      <td>-11.429310</td>\n",
       "      <td>...</td>\n",
       "      <td>7.507843e-06</td>\n",
       "      <td>7.083778e-06</td>\n",
       "      <td>6.728964e-06</td>\n",
       "      <td>6.445035e-06</td>\n",
       "      <td>6.208104e-06</td>\n",
       "      <td>6.011506e-06</td>\n",
       "      <td>5.857601e-06</td>\n",
       "      <td>5.736358e-06</td>\n",
       "      <td>5.654464e-06</td>\n",
       "      <td>5.600895e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-192.768143</td>\n",
       "      <td>116.761581</td>\n",
       "      <td>8.483458</td>\n",
       "      <td>39.969315</td>\n",
       "      <td>-18.644230</td>\n",
       "      <td>30.744694</td>\n",
       "      <td>-20.441114</td>\n",
       "      <td>-3.995106</td>\n",
       "      <td>-4.845390</td>\n",
       "      <td>-27.480997</td>\n",
       "      <td>...</td>\n",
       "      <td>1.530146e-05</td>\n",
       "      <td>1.439213e-05</td>\n",
       "      <td>1.363423e-05</td>\n",
       "      <td>1.303029e-05</td>\n",
       "      <td>1.252546e-05</td>\n",
       "      <td>1.211058e-05</td>\n",
       "      <td>1.178593e-05</td>\n",
       "      <td>1.153132e-05</td>\n",
       "      <td>1.135512e-05</td>\n",
       "      <td>1.124303e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>-170.995926</td>\n",
       "      <td>131.567947</td>\n",
       "      <td>4.367309</td>\n",
       "      <td>34.149075</td>\n",
       "      <td>-21.463945</td>\n",
       "      <td>19.826168</td>\n",
       "      <td>-9.597502</td>\n",
       "      <td>-8.316634</td>\n",
       "      <td>2.036535</td>\n",
       "      <td>-17.701063</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125740e-06</td>\n",
       "      <td>1.064263e-06</td>\n",
       "      <td>1.011978e-06</td>\n",
       "      <td>9.696928e-07</td>\n",
       "      <td>9.341181e-07</td>\n",
       "      <td>9.046452e-07</td>\n",
       "      <td>8.812943e-07</td>\n",
       "      <td>8.630064e-07</td>\n",
       "      <td>8.504387e-07</td>\n",
       "      <td>8.422486e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>-276.502716</td>\n",
       "      <td>135.377914</td>\n",
       "      <td>10.197211</td>\n",
       "      <td>30.170574</td>\n",
       "      <td>-22.439758</td>\n",
       "      <td>6.364676</td>\n",
       "      <td>-15.692318</td>\n",
       "      <td>-24.409771</td>\n",
       "      <td>0.408411</td>\n",
       "      <td>-8.242374</td>\n",
       "      <td>...</td>\n",
       "      <td>2.322224e-06</td>\n",
       "      <td>2.187234e-06</td>\n",
       "      <td>2.074446e-06</td>\n",
       "      <td>1.984408e-06</td>\n",
       "      <td>1.909373e-06</td>\n",
       "      <td>1.847081e-06</td>\n",
       "      <td>1.798585e-06</td>\n",
       "      <td>1.760399e-06</td>\n",
       "      <td>1.734200e-06</td>\n",
       "      <td>1.717432e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>-203.477753</td>\n",
       "      <td>148.898331</td>\n",
       "      <td>3.335640</td>\n",
       "      <td>31.260937</td>\n",
       "      <td>-23.842278</td>\n",
       "      <td>10.415450</td>\n",
       "      <td>-18.996857</td>\n",
       "      <td>-33.429424</td>\n",
       "      <td>-3.545755</td>\n",
       "      <td>-22.562578</td>\n",
       "      <td>...</td>\n",
       "      <td>4.251870e-07</td>\n",
       "      <td>3.897166e-07</td>\n",
       "      <td>3.615536e-07</td>\n",
       "      <td>3.396982e-07</td>\n",
       "      <td>3.221379e-07</td>\n",
       "      <td>3.080289e-07</td>\n",
       "      <td>2.970529e-07</td>\n",
       "      <td>2.887397e-07</td>\n",
       "      <td>2.830752e-07</td>\n",
       "      <td>2.793792e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>-278.188599</td>\n",
       "      <td>115.198441</td>\n",
       "      <td>15.943944</td>\n",
       "      <td>58.600094</td>\n",
       "      <td>-32.497604</td>\n",
       "      <td>25.483486</td>\n",
       "      <td>-7.505641</td>\n",
       "      <td>-18.275711</td>\n",
       "      <td>4.931672</td>\n",
       "      <td>-24.413553</td>\n",
       "      <td>...</td>\n",
       "      <td>1.841635e-06</td>\n",
       "      <td>1.731091e-06</td>\n",
       "      <td>1.639023e-06</td>\n",
       "      <td>1.565354e-06</td>\n",
       "      <td>1.504025e-06</td>\n",
       "      <td>1.453219e-06</td>\n",
       "      <td>1.413930e-06</td>\n",
       "      <td>1.382906e-06</td>\n",
       "      <td>1.361379e-06</td>\n",
       "      <td>1.347869e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>-184.132843</td>\n",
       "      <td>123.413986</td>\n",
       "      <td>4.582660</td>\n",
       "      <td>37.225571</td>\n",
       "      <td>-14.746784</td>\n",
       "      <td>16.139269</td>\n",
       "      <td>-6.398055</td>\n",
       "      <td>-3.158630</td>\n",
       "      <td>1.546444</td>\n",
       "      <td>-15.234117</td>\n",
       "      <td>...</td>\n",
       "      <td>3.705386e-06</td>\n",
       "      <td>3.489993e-06</td>\n",
       "      <td>3.310121e-06</td>\n",
       "      <td>3.166341e-06</td>\n",
       "      <td>3.046358e-06</td>\n",
       "      <td>2.947753e-06</td>\n",
       "      <td>2.869736e-06</td>\n",
       "      <td>2.808954e-06</td>\n",
       "      <td>2.767362e-06</td>\n",
       "      <td>2.740277e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2244 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2          3          4          5    \\\n",
       "0    -256.103912   98.469414  22.013477  52.473427 -19.976601  12.298381   \n",
       "1    -300.186493   85.507095  20.787426  23.039135   2.667248  13.296325   \n",
       "2    -157.332275  127.011574  -5.880052  43.091164 -18.972185  23.088911   \n",
       "3    -276.085114  133.718170  27.578678  36.164024   1.329927  -0.267277   \n",
       "4    -192.768143  116.761581   8.483458  39.969315 -18.644230  30.744694   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "2239 -170.995926  131.567947   4.367309  34.149075 -21.463945  19.826168   \n",
       "2240 -276.502716  135.377914  10.197211  30.170574 -22.439758   6.364676   \n",
       "2241 -203.477753  148.898331   3.335640  31.260937 -23.842278  10.415450   \n",
       "2242 -278.188599  115.198441  15.943944  58.600094 -32.497604  25.483486   \n",
       "2243 -184.132843  123.413986   4.582660  37.225571 -14.746784  16.139269   \n",
       "\n",
       "            6          7         8          9    ...           143  \\\n",
       "0    -13.486473 -21.096678 -8.685554 -14.394847  ...  5.152135e-06   \n",
       "1     -2.531562   1.466273 -0.258310  -9.347284  ...  1.021982e-05   \n",
       "2    -13.768730 -11.887770 -1.636095 -30.187855  ...  3.442305e-06   \n",
       "3     -0.001654 -10.962516 -5.820240 -11.429310  ...  7.507843e-06   \n",
       "4    -20.441114  -3.995106 -4.845390 -27.480997  ...  1.530146e-05   \n",
       "...         ...        ...       ...        ...  ...           ...   \n",
       "2239  -9.597502  -8.316634  2.036535 -17.701063  ...  1.125740e-06   \n",
       "2240 -15.692318 -24.409771  0.408411  -8.242374  ...  2.322224e-06   \n",
       "2241 -18.996857 -33.429424 -3.545755 -22.562578  ...  4.251870e-07   \n",
       "2242  -7.505641 -18.275711  4.931672 -24.413553  ...  1.841635e-06   \n",
       "2243  -6.398055  -3.158630  1.546444 -15.234117  ...  3.705386e-06   \n",
       "\n",
       "               144           145           146           147           148  \\\n",
       "0     4.850130e-06  4.598218e-06  4.396695e-06  4.228468e-06  4.089994e-06   \n",
       "1     9.616067e-06  9.112850e-06  8.710424e-06  8.375203e-06  8.097788e-06   \n",
       "2     3.239278e-06  3.070470e-06  2.935717e-06  2.823577e-06  2.731393e-06   \n",
       "3     7.083778e-06  6.728964e-06  6.445035e-06  6.208104e-06  6.011506e-06   \n",
       "4     1.439213e-05  1.363423e-05  1.303029e-05  1.252546e-05  1.211058e-05   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2239  1.064263e-06  1.011978e-06  9.696928e-07  9.341181e-07  9.046452e-07   \n",
       "2240  2.187234e-06  2.074446e-06  1.984408e-06  1.909373e-06  1.847081e-06   \n",
       "2241  3.897166e-07  3.615536e-07  3.396982e-07  3.221379e-07  3.080289e-07   \n",
       "2242  1.731091e-06  1.639023e-06  1.565354e-06  1.504025e-06  1.453219e-06   \n",
       "2243  3.489993e-06  3.310121e-06  3.166341e-06  3.046358e-06  2.947753e-06   \n",
       "\n",
       "               149           150           151           152  \n",
       "0     3.981520e-06  3.896523e-06  3.837688e-06  3.799962e-06  \n",
       "1     7.881747e-06  7.711950e-06  7.595052e-06  7.520370e-06  \n",
       "2     2.658706e-06  2.602187e-06  2.563323e-06  2.538142e-06  \n",
       "3     5.857601e-06  5.736358e-06  5.654464e-06  5.600895e-06  \n",
       "4     1.178593e-05  1.153132e-05  1.135512e-05  1.124303e-05  \n",
       "...            ...           ...           ...           ...  \n",
       "2239  8.812943e-07  8.630064e-07  8.504387e-07  8.422486e-07  \n",
       "2240  1.798585e-06  1.760399e-06  1.734200e-06  1.717432e-06  \n",
       "2241  2.970529e-07  2.887397e-07  2.830752e-07  2.793792e-07  \n",
       "2242  1.413930e-06  1.382906e-06  1.361379e-06  1.347869e-06  \n",
       "2243  2.869736e-06  2.808954e-06  2.767362e-06  2.740277e-06  \n",
       "\n",
       "[2244 rows x 153 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4025ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "05678594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Input, Dense,Conv1D,MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a4a2b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "723b4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], 1))\n",
    "    ,\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer='l1')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a4558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "287ed2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 8s 10ms/step - loss: 0.7051 - accuracy: 0.6151\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.6585 - accuracy: 0.6562\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.5813 - accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.4946 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.4560 - accuracy: 0.7979\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.4334 - accuracy: 0.8065\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.4096 - accuracy: 0.8238\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.3933 - accuracy: 0.8302\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.3854 - accuracy: 0.8391\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 0.3678 - accuracy: 0.8501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204c7f9e4a0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=10, batch_size=32, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1c2c5e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1394 - accuracy: 0.9545 - val_loss: 0.7335 - val_accuracy: 0.7341\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1466 - accuracy: 0.9533 - val_loss: 0.6948 - val_accuracy: 0.7059\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1252 - accuracy: 0.9613 - val_loss: 0.5975 - val_accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1108 - accuracy: 0.9639 - val_loss: 1.3922 - val_accuracy: 0.6679\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1119 - accuracy: 0.9646 - val_loss: 1.4567 - val_accuracy: 0.5919\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1229 - accuracy: 0.9589 - val_loss: 0.5781 - val_accuracy: 0.7892\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1293 - accuracy: 0.9583 - val_loss: 0.9564 - val_accuracy: 0.7108\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1062 - accuracy: 0.9675 - val_loss: 1.0088 - val_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1075 - accuracy: 0.9674 - val_loss: 0.8168 - val_accuracy: 0.6985\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 0.1059 - accuracy: 0.9655 - val_loss: 0.5854 - val_accuracy: 0.8113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206dac89a20>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=10, batch_size=32,validation_data=(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ce6c45d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "160/160 [==============================] - 3s 13ms/step - loss: 0.2265 - accuracy: 0.9199 - val_loss: 0.2569 - val_accuracy: 0.9042\n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.2189 - accuracy: 0.9242 - val_loss: 0.3068 - val_accuracy: 0.8899\n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.2102 - accuracy: 0.9263 - val_loss: 0.2603 - val_accuracy: 0.9055\n",
      "Epoch 4/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.2133 - accuracy: 0.9288 - val_loss: 0.2492 - val_accuracy: 0.9131\n",
      "Epoch 5/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.2087 - accuracy: 0.9303 - val_loss: 0.2619 - val_accuracy: 0.9024\n",
      "Epoch 6/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.2053 - accuracy: 0.9297 - val_loss: 0.2203 - val_accuracy: 0.9176\n",
      "Epoch 7/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1964 - accuracy: 0.9351 - val_loss: 0.2227 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1966 - accuracy: 0.9324 - val_loss: 0.2448 - val_accuracy: 0.9113\n",
      "Epoch 9/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1972 - accuracy: 0.9324 - val_loss: 0.2158 - val_accuracy: 0.9202\n",
      "Epoch 10/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1900 - accuracy: 0.9377 - val_loss: 0.2236 - val_accuracy: 0.9176\n",
      "Epoch 11/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1877 - accuracy: 0.9383 - val_loss: 0.2326 - val_accuracy: 0.9193\n",
      "Epoch 12/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1900 - accuracy: 0.9375 - val_loss: 0.2096 - val_accuracy: 0.9278\n",
      "Epoch 13/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1844 - accuracy: 0.9383 - val_loss: 0.2273 - val_accuracy: 0.9225\n",
      "Epoch 14/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1832 - accuracy: 0.9400 - val_loss: 0.2005 - val_accuracy: 0.9274\n",
      "Epoch 15/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1765 - accuracy: 0.9413 - val_loss: 0.2145 - val_accuracy: 0.9242\n",
      "Epoch 16/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1706 - accuracy: 0.9433 - val_loss: 0.2009 - val_accuracy: 0.9296\n",
      "Epoch 17/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1714 - accuracy: 0.9448 - val_loss: 0.2160 - val_accuracy: 0.9211\n",
      "Epoch 18/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1699 - accuracy: 0.9430 - val_loss: 0.2077 - val_accuracy: 0.9274\n",
      "Epoch 19/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1632 - accuracy: 0.9470 - val_loss: 0.1933 - val_accuracy: 0.9318\n",
      "Epoch 20/20\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1675 - accuracy: 0.9450 - val_loss: 0.1938 - val_accuracy: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204c8030d60>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=20, batch_size=64,validation_data=(X_val,y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "68235249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1761 - accuracy: 0.9409 - val_loss: 0.2059 - val_accuracy: 0.9283\n",
      "Epoch 2/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1518 - accuracy: 0.9511 - val_loss: 0.1940 - val_accuracy: 0.9274\n",
      "Epoch 3/30\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1557 - accuracy: 0.9472 - val_loss: 0.2015 - val_accuracy: 0.9300\n",
      "Epoch 4/30\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1513 - accuracy: 0.9500 - val_loss: 0.2243 - val_accuracy: 0.9211\n",
      "Epoch 5/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1557 - accuracy: 0.9494 - val_loss: 0.1833 - val_accuracy: 0.9381\n",
      "Epoch 6/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1499 - accuracy: 0.9544 - val_loss: 0.2265 - val_accuracy: 0.9247\n",
      "Epoch 7/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1527 - accuracy: 0.9510 - val_loss: 0.1926 - val_accuracy: 0.9363\n",
      "Epoch 8/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1536 - accuracy: 0.9495 - val_loss: 0.1800 - val_accuracy: 0.9403\n",
      "Epoch 9/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1406 - accuracy: 0.9550 - val_loss: 0.1807 - val_accuracy: 0.9358\n",
      "Epoch 10/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1405 - accuracy: 0.9556 - val_loss: 0.1719 - val_accuracy: 0.9403\n",
      "Epoch 11/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1352 - accuracy: 0.9568 - val_loss: 0.2108 - val_accuracy: 0.9269\n",
      "Epoch 12/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1312 - accuracy: 0.9580 - val_loss: 0.2116 - val_accuracy: 0.9381\n",
      "Epoch 13/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1265 - accuracy: 0.9589 - val_loss: 0.1831 - val_accuracy: 0.9456\n",
      "Epoch 14/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1301 - accuracy: 0.9591 - val_loss: 0.1771 - val_accuracy: 0.9465\n",
      "Epoch 15/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1229 - accuracy: 0.9613 - val_loss: 0.1965 - val_accuracy: 0.9403\n",
      "Epoch 16/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1220 - accuracy: 0.9622 - val_loss: 0.1758 - val_accuracy: 0.9403\n",
      "Epoch 17/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1290 - accuracy: 0.9615 - val_loss: 0.1761 - val_accuracy: 0.9394\n",
      "Epoch 18/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1230 - accuracy: 0.9626 - val_loss: 0.1820 - val_accuracy: 0.9381\n",
      "Epoch 19/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1195 - accuracy: 0.9622 - val_loss: 0.1887 - val_accuracy: 0.9479\n",
      "Epoch 20/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1177 - accuracy: 0.9629 - val_loss: 0.1835 - val_accuracy: 0.9407\n",
      "Epoch 21/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1201 - accuracy: 0.9622 - val_loss: 0.1747 - val_accuracy: 0.9434\n",
      "Epoch 22/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1113 - accuracy: 0.9659 - val_loss: 0.1873 - val_accuracy: 0.9421\n",
      "Epoch 23/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1113 - accuracy: 0.9659 - val_loss: 0.1910 - val_accuracy: 0.9389\n",
      "Epoch 24/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1075 - accuracy: 0.9672 - val_loss: 0.2407 - val_accuracy: 0.9394\n",
      "Epoch 25/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1143 - accuracy: 0.9631 - val_loss: 0.1812 - val_accuracy: 0.9372\n",
      "Epoch 26/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1118 - accuracy: 0.9649 - val_loss: 0.1758 - val_accuracy: 0.9394\n",
      "Epoch 27/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1114 - accuracy: 0.9672 - val_loss: 0.1946 - val_accuracy: 0.9479\n",
      "Epoch 28/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1061 - accuracy: 0.9687 - val_loss: 0.1865 - val_accuracy: 0.9447\n",
      "Epoch 29/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.1034 - accuracy: 0.9658 - val_loss: 0.1992 - val_accuracy: 0.9398\n",
      "Epoch 30/30\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0929 - accuracy: 0.9708 - val_loss: 0.1835 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204bd686050>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=30, batch_size=64,validation_data=(X_val,y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56eb0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eaea115",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c97f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24a82d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6515478056426333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd807a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546345811051694"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5de1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdd0dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=NearestNeighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abc2272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "521f12e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NearestNeighbors' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m(X_train,y_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NearestNeighbors' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27e5f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284313725490197"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11a2783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da176dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc8fc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cb65746",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 3  # Adjust based on experimentation\n",
    "covariance_type = 'full'  # Adjust based on experimentation\n",
    "max_iterations = 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfa1aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e766ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=num_components, covariance_type=covariance_type, max_iter=max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7029066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(n_components=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(n_components=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianMixture(n_components=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aca8ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gmm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af73c1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4344601679416915"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.score(X_train_scaled,X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5818a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2a4da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35962566844919786\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57f476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7a9073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='rbf', C=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a63f9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aea0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b8720b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532085561497327\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7cd10f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761951410658307"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19fd3398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532085561497327"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "319e433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6aa75d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9184491978609626\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn_classifier.predict(X_test_scaled)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(f\"KNN Accuracy: {knn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd32fddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441614420062696"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "edd9c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184491978609626"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42b7d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4714af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HistGradientBoostingClassifier(\n",
    "    max_iter=1,\n",
    "    max_depth=5,    # Control the maximum depth of each estimator\n",
    "    learning_rate=0.2, \n",
    "    min_samples_leaf=10,  # Set a minimum number of samples required to be at a leaf node\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "995cb2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "898d0070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964733542319749"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "220e8aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625668449197861"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e1e0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=clf1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7196453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb Accuracy: 0.9184491978609626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb_accuracy = accuracy_score(y_test, a)\n",
    "print(f\"gb Accuracy: {knn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f6c3eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path2=\"for-rerecorded/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2164e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"fake\", \"real\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4cba319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data_path, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder in enumerate(labels):\n",
    "        for filename in os.listdir(os.path.join(data_path, folder)):\n",
    "            file_path = os.path.join(data_path, folder, filename)\n",
    "            features = extract_features(file_path)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8def8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = preprocess_dataset(data_path2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cb7228c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y2)\n",
    "y2 = lb.transform(y2)\n",
    "y2 = y2.ravel()\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f21ec5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b213fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "605b07f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-158.425888</td>\n",
       "      <td>143.737640</td>\n",
       "      <td>-3.421895</td>\n",
       "      <td>23.124899</td>\n",
       "      <td>-15.193885</td>\n",
       "      <td>24.818220</td>\n",
       "      <td>-10.542620</td>\n",
       "      <td>-9.289985</td>\n",
       "      <td>-0.849831</td>\n",
       "      <td>-19.399073</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712595e-06</td>\n",
       "      <td>1.609247e-06</td>\n",
       "      <td>1.523417e-06</td>\n",
       "      <td>1.454864e-06</td>\n",
       "      <td>1.397858e-06</td>\n",
       "      <td>1.350945e-06</td>\n",
       "      <td>1.314226e-06</td>\n",
       "      <td>1.285638e-06</td>\n",
       "      <td>1.265734e-06</td>\n",
       "      <td>1.253083e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-162.403244</td>\n",
       "      <td>144.773376</td>\n",
       "      <td>3.088728</td>\n",
       "      <td>29.386974</td>\n",
       "      <td>-12.531352</td>\n",
       "      <td>20.539282</td>\n",
       "      <td>-9.818403</td>\n",
       "      <td>-7.625255</td>\n",
       "      <td>-5.300449</td>\n",
       "      <td>-23.327536</td>\n",
       "      <td>...</td>\n",
       "      <td>4.567614e-06</td>\n",
       "      <td>4.308221e-06</td>\n",
       "      <td>4.090845e-06</td>\n",
       "      <td>3.916583e-06</td>\n",
       "      <td>3.770861e-06</td>\n",
       "      <td>3.651247e-06</td>\n",
       "      <td>3.556295e-06</td>\n",
       "      <td>3.482241e-06</td>\n",
       "      <td>3.431439e-06</td>\n",
       "      <td>3.398399e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-165.431015</td>\n",
       "      <td>136.146378</td>\n",
       "      <td>-3.314423</td>\n",
       "      <td>42.388786</td>\n",
       "      <td>-16.870707</td>\n",
       "      <td>23.915314</td>\n",
       "      <td>-18.782120</td>\n",
       "      <td>-14.293229</td>\n",
       "      <td>-8.698584</td>\n",
       "      <td>-27.430391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363575e-06</td>\n",
       "      <td>1.289662e-06</td>\n",
       "      <td>1.227146e-06</td>\n",
       "      <td>1.176609e-06</td>\n",
       "      <td>1.134309e-06</td>\n",
       "      <td>1.099032e-06</td>\n",
       "      <td>1.071235e-06</td>\n",
       "      <td>1.049495e-06</td>\n",
       "      <td>1.034390e-06</td>\n",
       "      <td>1.024666e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-146.756409</td>\n",
       "      <td>144.073120</td>\n",
       "      <td>-3.665487</td>\n",
       "      <td>30.452641</td>\n",
       "      <td>-19.225594</td>\n",
       "      <td>21.058481</td>\n",
       "      <td>-9.573334</td>\n",
       "      <td>-6.169008</td>\n",
       "      <td>-3.430728</td>\n",
       "      <td>-23.158026</td>\n",
       "      <td>...</td>\n",
       "      <td>5.725443e-06</td>\n",
       "      <td>5.257770e-06</td>\n",
       "      <td>4.878174e-06</td>\n",
       "      <td>4.577393e-06</td>\n",
       "      <td>4.331780e-06</td>\n",
       "      <td>4.132319e-06</td>\n",
       "      <td>3.979466e-06</td>\n",
       "      <td>3.861586e-06</td>\n",
       "      <td>3.777597e-06</td>\n",
       "      <td>3.728496e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-171.529465</td>\n",
       "      <td>160.476868</td>\n",
       "      <td>-13.078272</td>\n",
       "      <td>26.888058</td>\n",
       "      <td>-20.511671</td>\n",
       "      <td>18.870352</td>\n",
       "      <td>-24.506311</td>\n",
       "      <td>-18.751568</td>\n",
       "      <td>-10.306947</td>\n",
       "      <td>-26.929226</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540792e-05</td>\n",
       "      <td>1.459046e-05</td>\n",
       "      <td>1.390033e-05</td>\n",
       "      <td>1.334531e-05</td>\n",
       "      <td>1.287893e-05</td>\n",
       "      <td>1.249118e-05</td>\n",
       "      <td>1.218819e-05</td>\n",
       "      <td>1.194861e-05</td>\n",
       "      <td>1.178375e-05</td>\n",
       "      <td>1.167697e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>-206.659378</td>\n",
       "      <td>121.433647</td>\n",
       "      <td>-0.320798</td>\n",
       "      <td>68.330048</td>\n",
       "      <td>-14.853692</td>\n",
       "      <td>16.166746</td>\n",
       "      <td>-8.066371</td>\n",
       "      <td>-22.559032</td>\n",
       "      <td>-17.679024</td>\n",
       "      <td>-24.006382</td>\n",
       "      <td>...</td>\n",
       "      <td>5.965944e-06</td>\n",
       "      <td>5.622901e-06</td>\n",
       "      <td>5.335919e-06</td>\n",
       "      <td>5.106075e-06</td>\n",
       "      <td>4.914223e-06</td>\n",
       "      <td>4.755546e-06</td>\n",
       "      <td>4.631253e-06</td>\n",
       "      <td>4.533654e-06</td>\n",
       "      <td>4.466728e-06</td>\n",
       "      <td>4.423576e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>-223.937439</td>\n",
       "      <td>138.260895</td>\n",
       "      <td>13.372982</td>\n",
       "      <td>30.227598</td>\n",
       "      <td>-34.127480</td>\n",
       "      <td>32.890003</td>\n",
       "      <td>-16.404003</td>\n",
       "      <td>-16.231743</td>\n",
       "      <td>0.697566</td>\n",
       "      <td>-18.107117</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968337e-06</td>\n",
       "      <td>9.239613e-06</td>\n",
       "      <td>8.647280e-06</td>\n",
       "      <td>8.179822e-06</td>\n",
       "      <td>7.797359e-06</td>\n",
       "      <td>7.486668e-06</td>\n",
       "      <td>7.245923e-06</td>\n",
       "      <td>7.058823e-06</td>\n",
       "      <td>6.929414e-06</td>\n",
       "      <td>6.847427e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>-191.158951</td>\n",
       "      <td>137.332672</td>\n",
       "      <td>11.960568</td>\n",
       "      <td>50.376057</td>\n",
       "      <td>-27.046873</td>\n",
       "      <td>18.494043</td>\n",
       "      <td>-9.001764</td>\n",
       "      <td>-17.273994</td>\n",
       "      <td>-22.594812</td>\n",
       "      <td>-22.798145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.927000e-06</td>\n",
       "      <td>7.510717e-06</td>\n",
       "      <td>7.160212e-06</td>\n",
       "      <td>6.878980e-06</td>\n",
       "      <td>6.643033e-06</td>\n",
       "      <td>6.445533e-06</td>\n",
       "      <td>6.292208e-06</td>\n",
       "      <td>6.170346e-06</td>\n",
       "      <td>6.086780e-06</td>\n",
       "      <td>6.032947e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-169.291580</td>\n",
       "      <td>144.783615</td>\n",
       "      <td>-1.863288</td>\n",
       "      <td>44.370647</td>\n",
       "      <td>-35.544731</td>\n",
       "      <td>9.208752</td>\n",
       "      <td>-22.272167</td>\n",
       "      <td>-15.503508</td>\n",
       "      <td>-2.217409</td>\n",
       "      <td>-21.822470</td>\n",
       "      <td>...</td>\n",
       "      <td>6.891764e-07</td>\n",
       "      <td>6.448542e-07</td>\n",
       "      <td>6.085008e-07</td>\n",
       "      <td>5.798059e-07</td>\n",
       "      <td>5.560444e-07</td>\n",
       "      <td>5.369048e-07</td>\n",
       "      <td>5.214650e-07</td>\n",
       "      <td>5.096961e-07</td>\n",
       "      <td>5.018591e-07</td>\n",
       "      <td>4.966183e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>-183.172272</td>\n",
       "      <td>161.067947</td>\n",
       "      <td>2.489607</td>\n",
       "      <td>47.417374</td>\n",
       "      <td>-20.204407</td>\n",
       "      <td>4.453347</td>\n",
       "      <td>-4.562777</td>\n",
       "      <td>-17.137804</td>\n",
       "      <td>-22.915905</td>\n",
       "      <td>-17.502466</td>\n",
       "      <td>...</td>\n",
       "      <td>7.241126e-06</td>\n",
       "      <td>6.820836e-06</td>\n",
       "      <td>6.470197e-06</td>\n",
       "      <td>6.189679e-06</td>\n",
       "      <td>5.955989e-06</td>\n",
       "      <td>5.762568e-06</td>\n",
       "      <td>5.611489e-06</td>\n",
       "      <td>5.492740e-06</td>\n",
       "      <td>5.411409e-06</td>\n",
       "      <td>5.359071e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5    \\\n",
       "0   -158.425888  143.737640  -3.421895  23.124899 -15.193885  24.818220   \n",
       "1   -162.403244  144.773376   3.088728  29.386974 -12.531352  20.539282   \n",
       "2   -165.431015  136.146378  -3.314423  42.388786 -16.870707  23.915314   \n",
       "3   -146.756409  144.073120  -3.665487  30.452641 -19.225594  21.058481   \n",
       "4   -171.529465  160.476868 -13.078272  26.888058 -20.511671  18.870352   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "811 -206.659378  121.433647  -0.320798  68.330048 -14.853692  16.166746   \n",
       "812 -223.937439  138.260895  13.372982  30.227598 -34.127480  32.890003   \n",
       "813 -191.158951  137.332672  11.960568  50.376057 -27.046873  18.494043   \n",
       "814 -169.291580  144.783615  -1.863288  44.370647 -35.544731   9.208752   \n",
       "815 -183.172272  161.067947   2.489607  47.417374 -20.204407   4.453347   \n",
       "\n",
       "           6          7          8          9    ...           143  \\\n",
       "0   -10.542620  -9.289985  -0.849831 -19.399073  ...  1.712595e-06   \n",
       "1    -9.818403  -7.625255  -5.300449 -23.327536  ...  4.567614e-06   \n",
       "2   -18.782120 -14.293229  -8.698584 -27.430391  ...  1.363575e-06   \n",
       "3    -9.573334  -6.169008  -3.430728 -23.158026  ...  5.725443e-06   \n",
       "4   -24.506311 -18.751568 -10.306947 -26.929226  ...  1.540792e-05   \n",
       "..         ...        ...        ...        ...  ...           ...   \n",
       "811  -8.066371 -22.559032 -17.679024 -24.006382  ...  5.965944e-06   \n",
       "812 -16.404003 -16.231743   0.697566 -18.107117  ...  9.968337e-06   \n",
       "813  -9.001764 -17.273994 -22.594812 -22.798145  ...  7.927000e-06   \n",
       "814 -22.272167 -15.503508  -2.217409 -21.822470  ...  6.891764e-07   \n",
       "815  -4.562777 -17.137804 -22.915905 -17.502466  ...  7.241126e-06   \n",
       "\n",
       "              144           145           146           147           148  \\\n",
       "0    1.609247e-06  1.523417e-06  1.454864e-06  1.397858e-06  1.350945e-06   \n",
       "1    4.308221e-06  4.090845e-06  3.916583e-06  3.770861e-06  3.651247e-06   \n",
       "2    1.289662e-06  1.227146e-06  1.176609e-06  1.134309e-06  1.099032e-06   \n",
       "3    5.257770e-06  4.878174e-06  4.577393e-06  4.331780e-06  4.132319e-06   \n",
       "4    1.459046e-05  1.390033e-05  1.334531e-05  1.287893e-05  1.249118e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "811  5.622901e-06  5.335919e-06  5.106075e-06  4.914223e-06  4.755546e-06   \n",
       "812  9.239613e-06  8.647280e-06  8.179822e-06  7.797359e-06  7.486668e-06   \n",
       "813  7.510717e-06  7.160212e-06  6.878980e-06  6.643033e-06  6.445533e-06   \n",
       "814  6.448542e-07  6.085008e-07  5.798059e-07  5.560444e-07  5.369048e-07   \n",
       "815  6.820836e-06  6.470197e-06  6.189679e-06  5.955989e-06  5.762568e-06   \n",
       "\n",
       "              149           150           151           152  \n",
       "0    1.314226e-06  1.285638e-06  1.265734e-06  1.253083e-06  \n",
       "1    3.556295e-06  3.482241e-06  3.431439e-06  3.398399e-06  \n",
       "2    1.071235e-06  1.049495e-06  1.034390e-06  1.024666e-06  \n",
       "3    3.979466e-06  3.861586e-06  3.777597e-06  3.728496e-06  \n",
       "4    1.218819e-05  1.194861e-05  1.178375e-05  1.167697e-05  \n",
       "..            ...           ...           ...           ...  \n",
       "811  4.631253e-06  4.533654e-06  4.466728e-06  4.423576e-06  \n",
       "812  7.245923e-06  7.058823e-06  6.929414e-06  6.847427e-06  \n",
       "813  6.292208e-06  6.170346e-06  6.086780e-06  6.032947e-06  \n",
       "814  5.214650e-07  5.096961e-07  5.018591e-07  4.966183e-07  \n",
       "815  5.611489e-06  5.492740e-06  5.411409e-06  5.359071e-06  \n",
       "\n",
       "[816 rows x 153 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "90850e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1b035a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "30df0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-158.425888</td>\n",
       "      <td>143.737640</td>\n",
       "      <td>-3.421895</td>\n",
       "      <td>23.124899</td>\n",
       "      <td>-15.193885</td>\n",
       "      <td>24.818220</td>\n",
       "      <td>-10.542620</td>\n",
       "      <td>-9.289985</td>\n",
       "      <td>-0.849831</td>\n",
       "      <td>-19.399073</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712595e-06</td>\n",
       "      <td>1.609247e-06</td>\n",
       "      <td>1.523417e-06</td>\n",
       "      <td>1.454864e-06</td>\n",
       "      <td>1.397858e-06</td>\n",
       "      <td>1.350945e-06</td>\n",
       "      <td>1.314226e-06</td>\n",
       "      <td>1.285638e-06</td>\n",
       "      <td>1.265734e-06</td>\n",
       "      <td>1.253083e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-162.403244</td>\n",
       "      <td>144.773376</td>\n",
       "      <td>3.088728</td>\n",
       "      <td>29.386974</td>\n",
       "      <td>-12.531352</td>\n",
       "      <td>20.539282</td>\n",
       "      <td>-9.818403</td>\n",
       "      <td>-7.625255</td>\n",
       "      <td>-5.300449</td>\n",
       "      <td>-23.327536</td>\n",
       "      <td>...</td>\n",
       "      <td>4.567614e-06</td>\n",
       "      <td>4.308221e-06</td>\n",
       "      <td>4.090845e-06</td>\n",
       "      <td>3.916583e-06</td>\n",
       "      <td>3.770861e-06</td>\n",
       "      <td>3.651247e-06</td>\n",
       "      <td>3.556295e-06</td>\n",
       "      <td>3.482241e-06</td>\n",
       "      <td>3.431439e-06</td>\n",
       "      <td>3.398399e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-165.431015</td>\n",
       "      <td>136.146378</td>\n",
       "      <td>-3.314423</td>\n",
       "      <td>42.388786</td>\n",
       "      <td>-16.870707</td>\n",
       "      <td>23.915314</td>\n",
       "      <td>-18.782120</td>\n",
       "      <td>-14.293229</td>\n",
       "      <td>-8.698584</td>\n",
       "      <td>-27.430391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363575e-06</td>\n",
       "      <td>1.289662e-06</td>\n",
       "      <td>1.227146e-06</td>\n",
       "      <td>1.176609e-06</td>\n",
       "      <td>1.134309e-06</td>\n",
       "      <td>1.099032e-06</td>\n",
       "      <td>1.071235e-06</td>\n",
       "      <td>1.049495e-06</td>\n",
       "      <td>1.034390e-06</td>\n",
       "      <td>1.024666e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-146.756409</td>\n",
       "      <td>144.073120</td>\n",
       "      <td>-3.665487</td>\n",
       "      <td>30.452641</td>\n",
       "      <td>-19.225594</td>\n",
       "      <td>21.058481</td>\n",
       "      <td>-9.573334</td>\n",
       "      <td>-6.169008</td>\n",
       "      <td>-3.430728</td>\n",
       "      <td>-23.158026</td>\n",
       "      <td>...</td>\n",
       "      <td>5.725443e-06</td>\n",
       "      <td>5.257770e-06</td>\n",
       "      <td>4.878174e-06</td>\n",
       "      <td>4.577393e-06</td>\n",
       "      <td>4.331780e-06</td>\n",
       "      <td>4.132319e-06</td>\n",
       "      <td>3.979466e-06</td>\n",
       "      <td>3.861586e-06</td>\n",
       "      <td>3.777597e-06</td>\n",
       "      <td>3.728496e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-171.529465</td>\n",
       "      <td>160.476868</td>\n",
       "      <td>-13.078272</td>\n",
       "      <td>26.888058</td>\n",
       "      <td>-20.511671</td>\n",
       "      <td>18.870352</td>\n",
       "      <td>-24.506311</td>\n",
       "      <td>-18.751568</td>\n",
       "      <td>-10.306947</td>\n",
       "      <td>-26.929226</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540792e-05</td>\n",
       "      <td>1.459046e-05</td>\n",
       "      <td>1.390033e-05</td>\n",
       "      <td>1.334531e-05</td>\n",
       "      <td>1.287893e-05</td>\n",
       "      <td>1.249118e-05</td>\n",
       "      <td>1.218819e-05</td>\n",
       "      <td>1.194861e-05</td>\n",
       "      <td>1.178375e-05</td>\n",
       "      <td>1.167697e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>-206.659378</td>\n",
       "      <td>121.433647</td>\n",
       "      <td>-0.320798</td>\n",
       "      <td>68.330048</td>\n",
       "      <td>-14.853692</td>\n",
       "      <td>16.166746</td>\n",
       "      <td>-8.066371</td>\n",
       "      <td>-22.559032</td>\n",
       "      <td>-17.679024</td>\n",
       "      <td>-24.006382</td>\n",
       "      <td>...</td>\n",
       "      <td>5.965944e-06</td>\n",
       "      <td>5.622901e-06</td>\n",
       "      <td>5.335919e-06</td>\n",
       "      <td>5.106075e-06</td>\n",
       "      <td>4.914223e-06</td>\n",
       "      <td>4.755546e-06</td>\n",
       "      <td>4.631253e-06</td>\n",
       "      <td>4.533654e-06</td>\n",
       "      <td>4.466728e-06</td>\n",
       "      <td>4.423576e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>-223.937439</td>\n",
       "      <td>138.260895</td>\n",
       "      <td>13.372982</td>\n",
       "      <td>30.227598</td>\n",
       "      <td>-34.127480</td>\n",
       "      <td>32.890003</td>\n",
       "      <td>-16.404003</td>\n",
       "      <td>-16.231743</td>\n",
       "      <td>0.697566</td>\n",
       "      <td>-18.107117</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968337e-06</td>\n",
       "      <td>9.239613e-06</td>\n",
       "      <td>8.647280e-06</td>\n",
       "      <td>8.179822e-06</td>\n",
       "      <td>7.797359e-06</td>\n",
       "      <td>7.486668e-06</td>\n",
       "      <td>7.245923e-06</td>\n",
       "      <td>7.058823e-06</td>\n",
       "      <td>6.929414e-06</td>\n",
       "      <td>6.847427e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>-191.158951</td>\n",
       "      <td>137.332672</td>\n",
       "      <td>11.960568</td>\n",
       "      <td>50.376057</td>\n",
       "      <td>-27.046873</td>\n",
       "      <td>18.494043</td>\n",
       "      <td>-9.001764</td>\n",
       "      <td>-17.273994</td>\n",
       "      <td>-22.594812</td>\n",
       "      <td>-22.798145</td>\n",
       "      <td>...</td>\n",
       "      <td>7.927000e-06</td>\n",
       "      <td>7.510717e-06</td>\n",
       "      <td>7.160212e-06</td>\n",
       "      <td>6.878980e-06</td>\n",
       "      <td>6.643033e-06</td>\n",
       "      <td>6.445533e-06</td>\n",
       "      <td>6.292208e-06</td>\n",
       "      <td>6.170346e-06</td>\n",
       "      <td>6.086780e-06</td>\n",
       "      <td>6.032947e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-169.291580</td>\n",
       "      <td>144.783615</td>\n",
       "      <td>-1.863288</td>\n",
       "      <td>44.370647</td>\n",
       "      <td>-35.544731</td>\n",
       "      <td>9.208752</td>\n",
       "      <td>-22.272167</td>\n",
       "      <td>-15.503508</td>\n",
       "      <td>-2.217409</td>\n",
       "      <td>-21.822470</td>\n",
       "      <td>...</td>\n",
       "      <td>6.891764e-07</td>\n",
       "      <td>6.448542e-07</td>\n",
       "      <td>6.085008e-07</td>\n",
       "      <td>5.798059e-07</td>\n",
       "      <td>5.560444e-07</td>\n",
       "      <td>5.369048e-07</td>\n",
       "      <td>5.214650e-07</td>\n",
       "      <td>5.096961e-07</td>\n",
       "      <td>5.018591e-07</td>\n",
       "      <td>4.966183e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>-183.172272</td>\n",
       "      <td>161.067947</td>\n",
       "      <td>2.489607</td>\n",
       "      <td>47.417374</td>\n",
       "      <td>-20.204407</td>\n",
       "      <td>4.453347</td>\n",
       "      <td>-4.562777</td>\n",
       "      <td>-17.137804</td>\n",
       "      <td>-22.915905</td>\n",
       "      <td>-17.502466</td>\n",
       "      <td>...</td>\n",
       "      <td>7.241126e-06</td>\n",
       "      <td>6.820836e-06</td>\n",
       "      <td>6.470197e-06</td>\n",
       "      <td>6.189679e-06</td>\n",
       "      <td>5.955989e-06</td>\n",
       "      <td>5.762568e-06</td>\n",
       "      <td>5.611489e-06</td>\n",
       "      <td>5.492740e-06</td>\n",
       "      <td>5.411409e-06</td>\n",
       "      <td>5.359071e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5    \\\n",
       "0   -158.425888  143.737640  -3.421895  23.124899 -15.193885  24.818220   \n",
       "1   -162.403244  144.773376   3.088728  29.386974 -12.531352  20.539282   \n",
       "2   -165.431015  136.146378  -3.314423  42.388786 -16.870707  23.915314   \n",
       "3   -146.756409  144.073120  -3.665487  30.452641 -19.225594  21.058481   \n",
       "4   -171.529465  160.476868 -13.078272  26.888058 -20.511671  18.870352   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "811 -206.659378  121.433647  -0.320798  68.330048 -14.853692  16.166746   \n",
       "812 -223.937439  138.260895  13.372982  30.227598 -34.127480  32.890003   \n",
       "813 -191.158951  137.332672  11.960568  50.376057 -27.046873  18.494043   \n",
       "814 -169.291580  144.783615  -1.863288  44.370647 -35.544731   9.208752   \n",
       "815 -183.172272  161.067947   2.489607  47.417374 -20.204407   4.453347   \n",
       "\n",
       "           6          7          8          9    ...           143  \\\n",
       "0   -10.542620  -9.289985  -0.849831 -19.399073  ...  1.712595e-06   \n",
       "1    -9.818403  -7.625255  -5.300449 -23.327536  ...  4.567614e-06   \n",
       "2   -18.782120 -14.293229  -8.698584 -27.430391  ...  1.363575e-06   \n",
       "3    -9.573334  -6.169008  -3.430728 -23.158026  ...  5.725443e-06   \n",
       "4   -24.506311 -18.751568 -10.306947 -26.929226  ...  1.540792e-05   \n",
       "..         ...        ...        ...        ...  ...           ...   \n",
       "811  -8.066371 -22.559032 -17.679024 -24.006382  ...  5.965944e-06   \n",
       "812 -16.404003 -16.231743   0.697566 -18.107117  ...  9.968337e-06   \n",
       "813  -9.001764 -17.273994 -22.594812 -22.798145  ...  7.927000e-06   \n",
       "814 -22.272167 -15.503508  -2.217409 -21.822470  ...  6.891764e-07   \n",
       "815  -4.562777 -17.137804 -22.915905 -17.502466  ...  7.241126e-06   \n",
       "\n",
       "              144           145           146           147           148  \\\n",
       "0    1.609247e-06  1.523417e-06  1.454864e-06  1.397858e-06  1.350945e-06   \n",
       "1    4.308221e-06  4.090845e-06  3.916583e-06  3.770861e-06  3.651247e-06   \n",
       "2    1.289662e-06  1.227146e-06  1.176609e-06  1.134309e-06  1.099032e-06   \n",
       "3    5.257770e-06  4.878174e-06  4.577393e-06  4.331780e-06  4.132319e-06   \n",
       "4    1.459046e-05  1.390033e-05  1.334531e-05  1.287893e-05  1.249118e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "811  5.622901e-06  5.335919e-06  5.106075e-06  4.914223e-06  4.755546e-06   \n",
       "812  9.239613e-06  8.647280e-06  8.179822e-06  7.797359e-06  7.486668e-06   \n",
       "813  7.510717e-06  7.160212e-06  6.878980e-06  6.643033e-06  6.445533e-06   \n",
       "814  6.448542e-07  6.085008e-07  5.798059e-07  5.560444e-07  5.369048e-07   \n",
       "815  6.820836e-06  6.470197e-06  6.189679e-06  5.955989e-06  5.762568e-06   \n",
       "\n",
       "              149           150           151           152  \n",
       "0    1.314226e-06  1.285638e-06  1.265734e-06  1.253083e-06  \n",
       "1    3.556295e-06  3.482241e-06  3.431439e-06  3.398399e-06  \n",
       "2    1.071235e-06  1.049495e-06  1.034390e-06  1.024666e-06  \n",
       "3    3.979466e-06  3.861586e-06  3.777597e-06  3.728496e-06  \n",
       "4    1.218819e-05  1.194861e-05  1.178375e-05  1.167697e-05  \n",
       "..            ...           ...           ...           ...  \n",
       "811  4.631253e-06  4.533654e-06  4.466728e-06  4.423576e-06  \n",
       "812  7.245923e-06  7.058823e-06  6.929414e-06  6.847427e-06  \n",
       "813  6.292208e-06  6.170346e-06  6.086780e-06  6.032947e-06  \n",
       "814  5.214650e-07  5.096961e-07  5.018591e-07  4.966183e-07  \n",
       "815  5.611489e-06  5.492740e-06  5.411409e-06  5.359071e-06  \n",
       "\n",
       "[816 rows x 153 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "385c3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5c8fb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3843 - accuracy: 0.6324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3842661380767822, 0.6323529481887817]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "27faa513",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7eb10c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[210 198]\n",
      " [ 60 348]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62       408\n",
      "           1       0.64      0.85      0.73       408\n",
      "\n",
      "    accuracy                           0.68       816\n",
      "   macro avg       0.71      0.68      0.67       816\n",
      "weighted avg       0.71      0.68      0.67       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "614f888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b9bd4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load('deepfakevoiceperhistboostinggrediant.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e18c5be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e6f86f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[210 198]\n",
      " [ 60 348]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62       408\n",
      "           1       0.64      0.85      0.73       408\n",
      "\n",
      "    accuracy                           0.68       816\n",
      "   macro avg       0.71      0.68      0.67       816\n",
      "weighted avg       0.71      0.68      0.67       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707df911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
