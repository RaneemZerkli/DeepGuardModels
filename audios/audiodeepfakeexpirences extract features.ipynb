{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e2f0ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"for-rerecorded/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b327f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2438f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, mfcc=True, chroma=True, mel=True):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    features = []\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
    "        features.extend(mfccs)\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate), axis=1)\n",
    "        features.extend(chroma)\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate), axis=1)\n",
    "        features.extend(mel)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5a6b8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6ba0982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data_path, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, folder in enumerate(labels):\n",
    "        for filename in os.listdir(os.path.join(data_path, folder)):\n",
    "            file_path = os.path.join(data_path, folder, filename)\n",
    "            features = extract_features(file_path)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1b9b10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  [\"FAKE\", \"REAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bfe1398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_dataset(data_path, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "30938fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "14543c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f9f201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1=\"for-rerecorded/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "39cbea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = preprocess_dataset(data_path1, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "103bd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "baf459d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8507e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7336bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-260.108490</td>\n",
       "      <td>100.856926</td>\n",
       "      <td>-25.453163</td>\n",
       "      <td>-0.269036</td>\n",
       "      <td>-15.496022</td>\n",
       "      <td>-11.916001</td>\n",
       "      <td>-12.884925</td>\n",
       "      <td>-5.138209</td>\n",
       "      <td>-15.833023</td>\n",
       "      <td>6.257811</td>\n",
       "      <td>...</td>\n",
       "      <td>9.336428e-03</td>\n",
       "      <td>6.195682e-03</td>\n",
       "      <td>3.594775e-03</td>\n",
       "      <td>2.233305e-03</td>\n",
       "      <td>9.730694e-04</td>\n",
       "      <td>2.946359e-04</td>\n",
       "      <td>4.892466e-05</td>\n",
       "      <td>3.269454e-06</td>\n",
       "      <td>6.663113e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-258.903595</td>\n",
       "      <td>93.914345</td>\n",
       "      <td>-27.627075</td>\n",
       "      <td>-1.932623</td>\n",
       "      <td>-13.113791</td>\n",
       "      <td>-17.308937</td>\n",
       "      <td>-16.980614</td>\n",
       "      <td>-6.160307</td>\n",
       "      <td>-13.806536</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549376e-03</td>\n",
       "      <td>3.796683e-03</td>\n",
       "      <td>2.303054e-03</td>\n",
       "      <td>1.080625e-03</td>\n",
       "      <td>5.009909e-04</td>\n",
       "      <td>1.425873e-04</td>\n",
       "      <td>2.037707e-05</td>\n",
       "      <td>1.444737e-06</td>\n",
       "      <td>7.402249e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-268.508942</td>\n",
       "      <td>118.533066</td>\n",
       "      <td>-38.892979</td>\n",
       "      <td>13.812951</td>\n",
       "      <td>0.954879</td>\n",
       "      <td>-9.624188</td>\n",
       "      <td>-7.970809</td>\n",
       "      <td>-5.041047</td>\n",
       "      <td>-15.510432</td>\n",
       "      <td>3.864957</td>\n",
       "      <td>...</td>\n",
       "      <td>8.331494e-04</td>\n",
       "      <td>6.335013e-04</td>\n",
       "      <td>6.894814e-04</td>\n",
       "      <td>3.921850e-04</td>\n",
       "      <td>1.752678e-04</td>\n",
       "      <td>4.481034e-05</td>\n",
       "      <td>6.480237e-06</td>\n",
       "      <td>4.081765e-07</td>\n",
       "      <td>8.685641e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-272.683777</td>\n",
       "      <td>101.505150</td>\n",
       "      <td>-22.251564</td>\n",
       "      <td>4.101077</td>\n",
       "      <td>-13.010054</td>\n",
       "      <td>-2.006705</td>\n",
       "      <td>-14.781232</td>\n",
       "      <td>-6.433926</td>\n",
       "      <td>-9.600471</td>\n",
       "      <td>-0.325104</td>\n",
       "      <td>...</td>\n",
       "      <td>4.412615e-03</td>\n",
       "      <td>2.272003e-03</td>\n",
       "      <td>1.896228e-03</td>\n",
       "      <td>1.035685e-03</td>\n",
       "      <td>4.408656e-04</td>\n",
       "      <td>1.162289e-04</td>\n",
       "      <td>1.642713e-05</td>\n",
       "      <td>1.276049e-06</td>\n",
       "      <td>2.311507e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-254.739319</td>\n",
       "      <td>66.810364</td>\n",
       "      <td>-33.194874</td>\n",
       "      <td>-4.094303</td>\n",
       "      <td>-21.525700</td>\n",
       "      <td>-7.582411</td>\n",
       "      <td>-17.506754</td>\n",
       "      <td>-6.246973</td>\n",
       "      <td>-16.661100</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>...</td>\n",
       "      <td>2.990989e-02</td>\n",
       "      <td>2.559934e-02</td>\n",
       "      <td>1.618331e-02</td>\n",
       "      <td>1.205126e-02</td>\n",
       "      <td>4.657575e-03</td>\n",
       "      <td>1.530605e-03</td>\n",
       "      <td>2.080529e-04</td>\n",
       "      <td>1.499762e-05</td>\n",
       "      <td>4.578604e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-248.250015</td>\n",
       "      <td>168.326218</td>\n",
       "      <td>-16.758812</td>\n",
       "      <td>21.825041</td>\n",
       "      <td>12.964885</td>\n",
       "      <td>-8.925458</td>\n",
       "      <td>-9.285087</td>\n",
       "      <td>-23.104162</td>\n",
       "      <td>-13.211295</td>\n",
       "      <td>-6.284047</td>\n",
       "      <td>...</td>\n",
       "      <td>4.022745e-07</td>\n",
       "      <td>3.031600e-07</td>\n",
       "      <td>2.081106e-07</td>\n",
       "      <td>1.265132e-07</td>\n",
       "      <td>6.556485e-08</td>\n",
       "      <td>3.465804e-08</td>\n",
       "      <td>2.404308e-08</td>\n",
       "      <td>2.144642e-08</td>\n",
       "      <td>2.064240e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-435.961487</td>\n",
       "      <td>109.968178</td>\n",
       "      <td>-36.460400</td>\n",
       "      <td>3.619920</td>\n",
       "      <td>-22.014071</td>\n",
       "      <td>2.735155</td>\n",
       "      <td>-12.598229</td>\n",
       "      <td>-1.886478</td>\n",
       "      <td>-8.125822</td>\n",
       "      <td>4.039160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.547929e-05</td>\n",
       "      <td>3.620403e-05</td>\n",
       "      <td>2.449301e-05</td>\n",
       "      <td>1.303550e-05</td>\n",
       "      <td>4.437405e-06</td>\n",
       "      <td>8.977966e-07</td>\n",
       "      <td>1.301831e-07</td>\n",
       "      <td>9.138097e-09</td>\n",
       "      <td>2.677586e-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-353.455017</td>\n",
       "      <td>102.869797</td>\n",
       "      <td>-17.037445</td>\n",
       "      <td>13.006072</td>\n",
       "      <td>-10.064619</td>\n",
       "      <td>3.232869</td>\n",
       "      <td>-26.687160</td>\n",
       "      <td>-9.108101</td>\n",
       "      <td>-20.111439</td>\n",
       "      <td>-6.876235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.135024e-03</td>\n",
       "      <td>1.139145e-03</td>\n",
       "      <td>9.070561e-04</td>\n",
       "      <td>4.304960e-04</td>\n",
       "      <td>1.650461e-04</td>\n",
       "      <td>5.302600e-05</td>\n",
       "      <td>1.001385e-05</td>\n",
       "      <td>7.888377e-07</td>\n",
       "      <td>1.590682e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-343.501312</td>\n",
       "      <td>48.163078</td>\n",
       "      <td>-7.313133</td>\n",
       "      <td>21.132427</td>\n",
       "      <td>-21.937901</td>\n",
       "      <td>-2.637476</td>\n",
       "      <td>-24.217213</td>\n",
       "      <td>-2.684844</td>\n",
       "      <td>-17.984877</td>\n",
       "      <td>-2.301978</td>\n",
       "      <td>...</td>\n",
       "      <td>5.645883e-03</td>\n",
       "      <td>4.428079e-03</td>\n",
       "      <td>3.275510e-03</td>\n",
       "      <td>2.032491e-03</td>\n",
       "      <td>8.294762e-04</td>\n",
       "      <td>2.311813e-04</td>\n",
       "      <td>3.600762e-05</td>\n",
       "      <td>2.545062e-06</td>\n",
       "      <td>6.667548e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-285.722809</td>\n",
       "      <td>86.296127</td>\n",
       "      <td>-29.728287</td>\n",
       "      <td>4.740103</td>\n",
       "      <td>-16.823217</td>\n",
       "      <td>-0.077320</td>\n",
       "      <td>-28.198235</td>\n",
       "      <td>-2.933665</td>\n",
       "      <td>-17.615633</td>\n",
       "      <td>-5.751049</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140047e-03</td>\n",
       "      <td>1.790365e-03</td>\n",
       "      <td>1.189014e-03</td>\n",
       "      <td>6.974210e-04</td>\n",
       "      <td>2.792055e-04</td>\n",
       "      <td>7.446736e-05</td>\n",
       "      <td>1.262077e-05</td>\n",
       "      <td>1.014096e-06</td>\n",
       "      <td>3.112910e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2          3          4          5  \\\n",
       "0  -260.108490  100.856926 -25.453163  -0.269036 -15.496022 -11.916001   \n",
       "1  -258.903595   93.914345 -27.627075  -1.932623 -13.113791 -17.308937   \n",
       "2  -268.508942  118.533066 -38.892979  13.812951   0.954879  -9.624188   \n",
       "3  -272.683777  101.505150 -22.251564   4.101077 -13.010054  -2.006705   \n",
       "4  -254.739319   66.810364 -33.194874  -4.094303 -21.525700  -7.582411   \n",
       "..         ...         ...        ...        ...        ...        ...   \n",
       "59 -248.250015  168.326218 -16.758812  21.825041  12.964885  -8.925458   \n",
       "60 -435.961487  109.968178 -36.460400   3.619920 -22.014071   2.735155   \n",
       "61 -353.455017  102.869797 -17.037445  13.006072 -10.064619   3.232869   \n",
       "62 -343.501312   48.163078  -7.313133  21.132427 -21.937901  -2.637476   \n",
       "63 -285.722809   86.296127 -29.728287   4.740103 -16.823217  -0.077320   \n",
       "\n",
       "            6          7          8         9  ...           144  \\\n",
       "0  -12.884925  -5.138209 -15.833023  6.257811  ...  9.336428e-03   \n",
       "1  -16.980614  -6.160307 -13.806536  0.112018  ...  3.549376e-03   \n",
       "2   -7.970809  -5.041047 -15.510432  3.864957  ...  8.331494e-04   \n",
       "3  -14.781232  -6.433926  -9.600471 -0.325104  ...  4.412615e-03   \n",
       "4  -17.506754  -6.246973 -16.661100  0.033362  ...  2.990989e-02   \n",
       "..        ...        ...        ...       ...  ...           ...   \n",
       "59  -9.285087 -23.104162 -13.211295 -6.284047  ...  4.022745e-07   \n",
       "60 -12.598229  -1.886478  -8.125822  4.039160  ...  4.547929e-05   \n",
       "61 -26.687160  -9.108101 -20.111439 -6.876235  ...  1.135024e-03   \n",
       "62 -24.217213  -2.684844 -17.984877 -2.301978  ...  5.645883e-03   \n",
       "63 -28.198235  -2.933665 -17.615633 -5.751049  ...  2.140047e-03   \n",
       "\n",
       "             145           146           147           148           149  \\\n",
       "0   6.195682e-03  3.594775e-03  2.233305e-03  9.730694e-04  2.946359e-04   \n",
       "1   3.796683e-03  2.303054e-03  1.080625e-03  5.009909e-04  1.425873e-04   \n",
       "2   6.335013e-04  6.894814e-04  3.921850e-04  1.752678e-04  4.481034e-05   \n",
       "3   2.272003e-03  1.896228e-03  1.035685e-03  4.408656e-04  1.162289e-04   \n",
       "4   2.559934e-02  1.618331e-02  1.205126e-02  4.657575e-03  1.530605e-03   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "59  3.031600e-07  2.081106e-07  1.265132e-07  6.556485e-08  3.465804e-08   \n",
       "60  3.620403e-05  2.449301e-05  1.303550e-05  4.437405e-06  8.977966e-07   \n",
       "61  1.139145e-03  9.070561e-04  4.304960e-04  1.650461e-04  5.302600e-05   \n",
       "62  4.428079e-03  3.275510e-03  2.032491e-03  8.294762e-04  2.311813e-04   \n",
       "63  1.790365e-03  1.189014e-03  6.974210e-04  2.792055e-04  7.446736e-05   \n",
       "\n",
       "             150           151           152  label  \n",
       "0   4.892466e-05  3.269454e-06  6.663113e-08      0  \n",
       "1   2.037707e-05  1.444737e-06  7.402249e-08      0  \n",
       "2   6.480237e-06  4.081765e-07  8.685641e-09      0  \n",
       "3   1.642713e-05  1.276049e-06  2.311507e-08      0  \n",
       "4   2.080529e-04  1.499762e-05  4.578604e-07      0  \n",
       "..           ...           ...           ...    ...  \n",
       "59  2.404308e-08  2.144642e-08  2.064240e-08      1  \n",
       "60  1.301831e-07  9.138097e-09  2.677586e-10      1  \n",
       "61  1.001385e-05  7.888377e-07  1.590682e-08      1  \n",
       "62  3.600762e-05  2.545062e-06  6.667548e-08      1  \n",
       "63  1.262077e-05  1.014096e-06  3.112910e-08      1  \n",
       "\n",
       "[64 rows x 154 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d195645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56\n",
       "1     8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0679004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c95c9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_df = pd.DataFrame({\n",
    "    'label': [0, 1],\n",
    "    'count': [56, 8]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcd0ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f84a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_resampled_over, y_resampled_over = oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e317accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-260.108490</td>\n",
       "      <td>100.856926</td>\n",
       "      <td>-25.453163</td>\n",
       "      <td>-0.269036</td>\n",
       "      <td>-15.496022</td>\n",
       "      <td>-11.916001</td>\n",
       "      <td>-12.884925</td>\n",
       "      <td>-5.138209</td>\n",
       "      <td>-15.833023</td>\n",
       "      <td>6.257811</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124242e-02</td>\n",
       "      <td>9.336428e-03</td>\n",
       "      <td>6.195682e-03</td>\n",
       "      <td>3.594775e-03</td>\n",
       "      <td>2.233305e-03</td>\n",
       "      <td>9.730694e-04</td>\n",
       "      <td>2.946359e-04</td>\n",
       "      <td>4.892466e-05</td>\n",
       "      <td>3.269454e-06</td>\n",
       "      <td>6.663113e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-258.903595</td>\n",
       "      <td>93.914345</td>\n",
       "      <td>-27.627075</td>\n",
       "      <td>-1.932623</td>\n",
       "      <td>-13.113791</td>\n",
       "      <td>-17.308937</td>\n",
       "      <td>-16.980614</td>\n",
       "      <td>-6.160307</td>\n",
       "      <td>-13.806536</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>...</td>\n",
       "      <td>7.814216e-03</td>\n",
       "      <td>3.549376e-03</td>\n",
       "      <td>3.796683e-03</td>\n",
       "      <td>2.303054e-03</td>\n",
       "      <td>1.080625e-03</td>\n",
       "      <td>5.009909e-04</td>\n",
       "      <td>1.425873e-04</td>\n",
       "      <td>2.037707e-05</td>\n",
       "      <td>1.444737e-06</td>\n",
       "      <td>7.402249e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-268.508942</td>\n",
       "      <td>118.533066</td>\n",
       "      <td>-38.892979</td>\n",
       "      <td>13.812951</td>\n",
       "      <td>0.954879</td>\n",
       "      <td>-9.624188</td>\n",
       "      <td>-7.970809</td>\n",
       "      <td>-5.041047</td>\n",
       "      <td>-15.510432</td>\n",
       "      <td>3.864957</td>\n",
       "      <td>...</td>\n",
       "      <td>9.703140e-04</td>\n",
       "      <td>8.331494e-04</td>\n",
       "      <td>6.335013e-04</td>\n",
       "      <td>6.894814e-04</td>\n",
       "      <td>3.921850e-04</td>\n",
       "      <td>1.752678e-04</td>\n",
       "      <td>4.481034e-05</td>\n",
       "      <td>6.480237e-06</td>\n",
       "      <td>4.081765e-07</td>\n",
       "      <td>8.685641e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-272.683777</td>\n",
       "      <td>101.505150</td>\n",
       "      <td>-22.251564</td>\n",
       "      <td>4.101077</td>\n",
       "      <td>-13.010054</td>\n",
       "      <td>-2.006705</td>\n",
       "      <td>-14.781232</td>\n",
       "      <td>-6.433926</td>\n",
       "      <td>-9.600471</td>\n",
       "      <td>-0.325104</td>\n",
       "      <td>...</td>\n",
       "      <td>4.850650e-03</td>\n",
       "      <td>4.412615e-03</td>\n",
       "      <td>2.272003e-03</td>\n",
       "      <td>1.896228e-03</td>\n",
       "      <td>1.035685e-03</td>\n",
       "      <td>4.408656e-04</td>\n",
       "      <td>1.162289e-04</td>\n",
       "      <td>1.642713e-05</td>\n",
       "      <td>1.276049e-06</td>\n",
       "      <td>2.311507e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-254.739319</td>\n",
       "      <td>66.810364</td>\n",
       "      <td>-33.194874</td>\n",
       "      <td>-4.094303</td>\n",
       "      <td>-21.525700</td>\n",
       "      <td>-7.582411</td>\n",
       "      <td>-17.506754</td>\n",
       "      <td>-6.246973</td>\n",
       "      <td>-16.661100</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>...</td>\n",
       "      <td>2.915999e-02</td>\n",
       "      <td>2.990989e-02</td>\n",
       "      <td>2.559934e-02</td>\n",
       "      <td>1.618331e-02</td>\n",
       "      <td>1.205126e-02</td>\n",
       "      <td>4.657575e-03</td>\n",
       "      <td>1.530605e-03</td>\n",
       "      <td>2.080529e-04</td>\n",
       "      <td>1.499762e-05</td>\n",
       "      <td>4.578604e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-285.722809</td>\n",
       "      <td>86.296127</td>\n",
       "      <td>-29.728287</td>\n",
       "      <td>4.740103</td>\n",
       "      <td>-16.823217</td>\n",
       "      <td>-0.077320</td>\n",
       "      <td>-28.198235</td>\n",
       "      <td>-2.933665</td>\n",
       "      <td>-17.615633</td>\n",
       "      <td>-5.751049</td>\n",
       "      <td>...</td>\n",
       "      <td>2.020439e-03</td>\n",
       "      <td>2.140047e-03</td>\n",
       "      <td>1.790365e-03</td>\n",
       "      <td>1.189014e-03</td>\n",
       "      <td>6.974210e-04</td>\n",
       "      <td>2.792055e-04</td>\n",
       "      <td>7.446736e-05</td>\n",
       "      <td>1.262077e-05</td>\n",
       "      <td>1.014096e-06</td>\n",
       "      <td>3.112910e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-248.250015</td>\n",
       "      <td>168.326218</td>\n",
       "      <td>-16.758812</td>\n",
       "      <td>21.825041</td>\n",
       "      <td>12.964885</td>\n",
       "      <td>-8.925458</td>\n",
       "      <td>-9.285087</td>\n",
       "      <td>-23.104162</td>\n",
       "      <td>-13.211295</td>\n",
       "      <td>-6.284047</td>\n",
       "      <td>...</td>\n",
       "      <td>4.886687e-07</td>\n",
       "      <td>4.022745e-07</td>\n",
       "      <td>3.031600e-07</td>\n",
       "      <td>2.081106e-07</td>\n",
       "      <td>1.265132e-07</td>\n",
       "      <td>6.556485e-08</td>\n",
       "      <td>3.465804e-08</td>\n",
       "      <td>2.404308e-08</td>\n",
       "      <td>2.144642e-08</td>\n",
       "      <td>2.064240e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-248.250015</td>\n",
       "      <td>168.326218</td>\n",
       "      <td>-16.758812</td>\n",
       "      <td>21.825041</td>\n",
       "      <td>12.964885</td>\n",
       "      <td>-8.925458</td>\n",
       "      <td>-9.285087</td>\n",
       "      <td>-23.104162</td>\n",
       "      <td>-13.211295</td>\n",
       "      <td>-6.284047</td>\n",
       "      <td>...</td>\n",
       "      <td>4.886687e-07</td>\n",
       "      <td>4.022745e-07</td>\n",
       "      <td>3.031600e-07</td>\n",
       "      <td>2.081106e-07</td>\n",
       "      <td>1.265132e-07</td>\n",
       "      <td>6.556485e-08</td>\n",
       "      <td>3.465804e-08</td>\n",
       "      <td>2.404308e-08</td>\n",
       "      <td>2.144642e-08</td>\n",
       "      <td>2.064240e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-285.722809</td>\n",
       "      <td>86.296127</td>\n",
       "      <td>-29.728287</td>\n",
       "      <td>4.740103</td>\n",
       "      <td>-16.823217</td>\n",
       "      <td>-0.077320</td>\n",
       "      <td>-28.198235</td>\n",
       "      <td>-2.933665</td>\n",
       "      <td>-17.615633</td>\n",
       "      <td>-5.751049</td>\n",
       "      <td>...</td>\n",
       "      <td>2.020439e-03</td>\n",
       "      <td>2.140047e-03</td>\n",
       "      <td>1.790365e-03</td>\n",
       "      <td>1.189014e-03</td>\n",
       "      <td>6.974210e-04</td>\n",
       "      <td>2.792055e-04</td>\n",
       "      <td>7.446736e-05</td>\n",
       "      <td>1.262077e-05</td>\n",
       "      <td>1.014096e-06</td>\n",
       "      <td>3.112910e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-343.501312</td>\n",
       "      <td>48.163078</td>\n",
       "      <td>-7.313133</td>\n",
       "      <td>21.132427</td>\n",
       "      <td>-21.937901</td>\n",
       "      <td>-2.637476</td>\n",
       "      <td>-24.217213</td>\n",
       "      <td>-2.684844</td>\n",
       "      <td>-17.984877</td>\n",
       "      <td>-2.301978</td>\n",
       "      <td>...</td>\n",
       "      <td>6.394251e-03</td>\n",
       "      <td>5.645883e-03</td>\n",
       "      <td>4.428079e-03</td>\n",
       "      <td>3.275510e-03</td>\n",
       "      <td>2.032491e-03</td>\n",
       "      <td>8.294762e-04</td>\n",
       "      <td>2.311813e-04</td>\n",
       "      <td>3.600762e-05</td>\n",
       "      <td>2.545062e-06</td>\n",
       "      <td>6.667548e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5    \\\n",
       "0   -260.108490  100.856926 -25.453163  -0.269036 -15.496022 -11.916001   \n",
       "1   -258.903595   93.914345 -27.627075  -1.932623 -13.113791 -17.308937   \n",
       "2   -268.508942  118.533066 -38.892979  13.812951   0.954879  -9.624188   \n",
       "3   -272.683777  101.505150 -22.251564   4.101077 -13.010054  -2.006705   \n",
       "4   -254.739319   66.810364 -33.194874  -4.094303 -21.525700  -7.582411   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "107 -285.722809   86.296127 -29.728287   4.740103 -16.823217  -0.077320   \n",
       "108 -248.250015  168.326218 -16.758812  21.825041  12.964885  -8.925458   \n",
       "109 -248.250015  168.326218 -16.758812  21.825041  12.964885  -8.925458   \n",
       "110 -285.722809   86.296127 -29.728287   4.740103 -16.823217  -0.077320   \n",
       "111 -343.501312   48.163078  -7.313133  21.132427 -21.937901  -2.637476   \n",
       "\n",
       "           6          7          8         9    ...           143  \\\n",
       "0   -12.884925  -5.138209 -15.833023  6.257811  ...  1.124242e-02   \n",
       "1   -16.980614  -6.160307 -13.806536  0.112018  ...  7.814216e-03   \n",
       "2    -7.970809  -5.041047 -15.510432  3.864957  ...  9.703140e-04   \n",
       "3   -14.781232  -6.433926  -9.600471 -0.325104  ...  4.850650e-03   \n",
       "4   -17.506754  -6.246973 -16.661100  0.033362  ...  2.915999e-02   \n",
       "..         ...        ...        ...       ...  ...           ...   \n",
       "107 -28.198235  -2.933665 -17.615633 -5.751049  ...  2.020439e-03   \n",
       "108  -9.285087 -23.104162 -13.211295 -6.284047  ...  4.886687e-07   \n",
       "109  -9.285087 -23.104162 -13.211295 -6.284047  ...  4.886687e-07   \n",
       "110 -28.198235  -2.933665 -17.615633 -5.751049  ...  2.020439e-03   \n",
       "111 -24.217213  -2.684844 -17.984877 -2.301978  ...  6.394251e-03   \n",
       "\n",
       "              144           145           146           147           148  \\\n",
       "0    9.336428e-03  6.195682e-03  3.594775e-03  2.233305e-03  9.730694e-04   \n",
       "1    3.549376e-03  3.796683e-03  2.303054e-03  1.080625e-03  5.009909e-04   \n",
       "2    8.331494e-04  6.335013e-04  6.894814e-04  3.921850e-04  1.752678e-04   \n",
       "3    4.412615e-03  2.272003e-03  1.896228e-03  1.035685e-03  4.408656e-04   \n",
       "4    2.990989e-02  2.559934e-02  1.618331e-02  1.205126e-02  4.657575e-03   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "107  2.140047e-03  1.790365e-03  1.189014e-03  6.974210e-04  2.792055e-04   \n",
       "108  4.022745e-07  3.031600e-07  2.081106e-07  1.265132e-07  6.556485e-08   \n",
       "109  4.022745e-07  3.031600e-07  2.081106e-07  1.265132e-07  6.556485e-08   \n",
       "110  2.140047e-03  1.790365e-03  1.189014e-03  6.974210e-04  2.792055e-04   \n",
       "111  5.645883e-03  4.428079e-03  3.275510e-03  2.032491e-03  8.294762e-04   \n",
       "\n",
       "              149           150           151           152  \n",
       "0    2.946359e-04  4.892466e-05  3.269454e-06  6.663113e-08  \n",
       "1    1.425873e-04  2.037707e-05  1.444737e-06  7.402249e-08  \n",
       "2    4.481034e-05  6.480237e-06  4.081765e-07  8.685641e-09  \n",
       "3    1.162289e-04  1.642713e-05  1.276049e-06  2.311507e-08  \n",
       "4    1.530605e-03  2.080529e-04  1.499762e-05  4.578604e-07  \n",
       "..            ...           ...           ...           ...  \n",
       "107  7.446736e-05  1.262077e-05  1.014096e-06  3.112910e-08  \n",
       "108  3.465804e-08  2.404308e-08  2.144642e-08  2.064240e-08  \n",
       "109  3.465804e-08  2.404308e-08  2.144642e-08  2.064240e-08  \n",
       "110  7.446736e-05  1.262077e-05  1.014096e-06  3.112910e-08  \n",
       "111  2.311813e-04  3.600762e-05  2.545062e-06  6.667548e-08  \n",
       "\n",
       "[112 rows x 153 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f311764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "107    1\n",
       "108    1\n",
       "109    1\n",
       "110    1\n",
       "111    1\n",
       "Name: label, Length: 112, dtype: int32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02c351e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(X_resampled_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "246361bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minai\\AppData\\Local\\Temp\\ipykernel_60112\\2252276333.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['label'] = y_resampled_over\n"
     ]
    }
   ],
   "source": [
    "df1['label'] = y_resampled_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1c3f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_resampled_over=X_resampled_over.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "665d8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6d86d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4275ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f570988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6fa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76a09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "810b9872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "611da0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9552311912225705"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8729fd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6066176470588235"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2fdb8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "918ac5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "64f12b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f545e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fdb0521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c765cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e153c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "38043fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1af7c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Input, Dense,Conv1D,MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2efbdad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "07154a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c1ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a50e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], 1))\n",
    "    ,\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer='l1')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd074be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b24e8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6877 - accuracy: 0.5393\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6858 - accuracy: 0.5393\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6702 - accuracy: 0.5843\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6426 - accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.6517\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6845 - accuracy: 0.6067\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6784 - accuracy: 0.6180\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6542 - accuracy: 0.6517\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.6629\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6744 - accuracy: 0.6629\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6198 - accuracy: 0.6517\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6518 - accuracy: 0.6180\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6498 - accuracy: 0.6180\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.6180\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6478 - accuracy: 0.6180\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.6180\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6312 - accuracy: 0.6292\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.6292\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6393 - accuracy: 0.6180\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6380 - accuracy: 0.6180\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6418 - accuracy: 0.6180\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6452 - accuracy: 0.6180\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6499 - accuracy: 0.6180\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.6404\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.6517\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.6517\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.6292\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6358 - accuracy: 0.6180\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.6180\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6248 - accuracy: 0.6292\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5857 - accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5679 - accuracy: 0.6966\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5664 - accuracy: 0.6966\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5759 - accuracy: 0.6854\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5779 - accuracy: 0.6854\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.6742\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5987 - accuracy: 0.6742\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5626 - accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5686 - accuracy: 0.6966\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5745 - accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5653 - accuracy: 0.6966\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5632 - accuracy: 0.6966\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5794 - accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5650 - accuracy: 0.6966\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5651 - accuracy: 0.6966\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.6966\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.6742\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5866 - accuracy: 0.6742\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.6854\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5795 - accuracy: 0.6854\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5875 - accuracy: 0.6854\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5794 - accuracy: 0.6854\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5834 - accuracy: 0.6854\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.6854\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5705 - accuracy: 0.6854\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5785 - accuracy: 0.6854\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5922 - accuracy: 0.6742\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5750 - accuracy: 0.6854\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5788 - accuracy: 0.6854\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5933 - accuracy: 0.6629\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.6629\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6036 - accuracy: 0.6629\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.6629\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5954 - accuracy: 0.6629\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5898 - accuracy: 0.6629\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5827 - accuracy: 0.6629\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5983 - accuracy: 0.6629\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6000 - accuracy: 0.6629\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.6629\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5984 - accuracy: 0.6629\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5897 - accuracy: 0.6629\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5866 - accuracy: 0.6629\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.6629\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.6629\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.6629\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5710 - accuracy: 0.6854\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5710 - accuracy: 0.6854\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5923 - accuracy: 0.6742\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5917 - accuracy: 0.6742\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5877 - accuracy: 0.6742\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5875 - accuracy: 0.6742\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5878 - accuracy: 0.6742\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5995 - accuracy: 0.6629\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5939 - accuracy: 0.6629\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6173 - accuracy: 0.6629\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.6629\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5809 - accuracy: 0.6742\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5685 - accuracy: 0.6854\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5833 - accuracy: 0.6742\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5947 - accuracy: 0.6742\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5850 - accuracy: 0.6742\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5922 - accuracy: 0.6742\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5823 - accuracy: 0.6742\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5994 - accuracy: 0.6629\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5882 - accuracy: 0.6629\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5956 - accuracy: 0.6629\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.6629\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.6629\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5930 - accuracy: 0.6629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20008f2f550>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=100, batch_size=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1585197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6064 - accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6163 - accuracy: 0.6404\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.6404\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.6292\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6197 - accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6283 - accuracy: 0.6292\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.6404\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5938 - accuracy: 0.6629\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5539 - accuracy: 0.7079\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5529 - accuracy: 0.7191\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.7079\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5661 - accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.6966\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5713 - accuracy: 0.6966\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5684 - accuracy: 0.6966\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5633 - accuracy: 0.6966\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.6966\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5654 - accuracy: 0.6966\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5421 - accuracy: 0.7191\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5469 - accuracy: 0.7191\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5477 - accuracy: 0.7191\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5646 - accuracy: 0.6966\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.6966\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5573 - accuracy: 0.6966\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5558 - accuracy: 0.6966\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5718 - accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5767 - accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5732 - accuracy: 0.6854\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5823 - accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.6966\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5814 - accuracy: 0.6966\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5395 - accuracy: 0.7191\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5550 - accuracy: 0.7079\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5642 - accuracy: 0.6966\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5637 - accuracy: 0.6966\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5670 - accuracy: 0.6966\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5605 - accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5704 - accuracy: 0.6966\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5590 - accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5675 - accuracy: 0.6966\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5615 - accuracy: 0.6966\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5642 - accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5685 - accuracy: 0.6966\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.6966\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5460 - accuracy: 0.7303\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0132 - accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6228 - accuracy: 0.7303\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6982 - accuracy: 0.5506\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5571 - accuracy: 0.7753\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5838 - accuracy: 0.7978\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.7753\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4767 - accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4497 - accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8315\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4738 - accuracy: 0.8315\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4443 - accuracy: 0.8315\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4668 - accuracy: 0.8315\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4782 - accuracy: 0.8315\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4611 - accuracy: 0.8202\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.8315\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4898 - accuracy: 0.8315\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5308 - accuracy: 0.8315\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4680 - accuracy: 0.8315\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4456 - accuracy: 0.8315\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4543 - accuracy: 0.8315\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4793 - accuracy: 0.8315\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.8315\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.8315\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.8315\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4881 - accuracy: 0.8315\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4994 - accuracy: 0.8315\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.8315\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4882 - accuracy: 0.8315\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4985 - accuracy: 0.8315\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4516 - accuracy: 0.8315\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4854 - accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4576 - accuracy: 0.8315\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4542 - accuracy: 0.8315\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4689 - accuracy: 0.8315\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.8315\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4724 - accuracy: 0.8315\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4819 - accuracy: 0.8315\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4919 - accuracy: 0.8315\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4822 - accuracy: 0.8315\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5037 - accuracy: 0.8315\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4564 - accuracy: 0.8315\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4715 - accuracy: 0.8315\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4779 - accuracy: 0.8315\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.8315\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4832 - accuracy: 0.8315\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5048 - accuracy: 0.8315\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4955 - accuracy: 0.8315\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5219 - accuracy: 0.8315\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4662 - accuracy: 0.8315\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4791 - accuracy: 0.8315\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5003 - accuracy: 0.8315\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4855 - accuracy: 0.8315\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4775 - accuracy: 0.8315\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2005df934c0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=100, batch_size=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fddc17d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4530 - accuracy: 0.8315\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5057 - accuracy: 0.8315\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.8315\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4337 - accuracy: 0.8315\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.8315\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4782 - accuracy: 0.8202\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4629 - accuracy: 0.8315\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4814 - accuracy: 0.8315\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4738 - accuracy: 0.8315\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5223 - accuracy: 0.8315\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4781 - accuracy: 0.8315\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4916 - accuracy: 0.8315\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4395 - accuracy: 0.8315\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4957 - accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4942 - accuracy: 0.8315\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4973 - accuracy: 0.8315\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5014 - accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4824 - accuracy: 0.8315\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4968 - accuracy: 0.8315\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4700 - accuracy: 0.8315\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4562 - accuracy: 0.8315\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5106 - accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5010 - accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.8315\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.8315\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.8315\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4601 - accuracy: 0.8315\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4713 - accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5326 - accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5206 - accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4980 - accuracy: 0.8315\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4985 - accuracy: 0.8315\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4667 - accuracy: 0.8315\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5153 - accuracy: 0.8315\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4831 - accuracy: 0.8315\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.8315\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4345 - accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4856 - accuracy: 0.8315\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5416 - accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4572 - accuracy: 0.8315\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4460 - accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4580 - accuracy: 0.8315\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4604 - accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4753 - accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4913 - accuracy: 0.8315\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4996 - accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5170 - accuracy: 0.8202\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4983 - accuracy: 0.8202\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5528 - accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5061 - accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4725 - accuracy: 0.8315\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5111 - accuracy: 0.8090\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.8090\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5041 - accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4547 - accuracy: 0.8315\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4681 - accuracy: 0.8090\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5179 - accuracy: 0.8202\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4751 - accuracy: 0.8315\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4774 - accuracy: 0.8315\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4809 - accuracy: 0.8202\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5066 - accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5037 - accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5188 - accuracy: 0.8202\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4717 - accuracy: 0.8315\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.8315\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4540 - accuracy: 0.8202\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5169 - accuracy: 0.8202\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5007 - accuracy: 0.8090\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5321 - accuracy: 0.8090\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5138 - accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.8315\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4815 - accuracy: 0.8202\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5129 - accuracy: 0.8090\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5042 - accuracy: 0.8090\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4801 - accuracy: 0.8202\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.8090\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5211 - accuracy: 0.8090\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5273 - accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5159 - accuracy: 0.8090\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5113 - accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5222 - accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5099 - accuracy: 0.8090\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.8090\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5175 - accuracy: 0.8090\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5219 - accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.8315\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5213 - accuracy: 0.8202\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4818 - accuracy: 0.8090\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4854 - accuracy: 0.8090\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5124 - accuracy: 0.8090\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5172 - accuracy: 0.8090\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5275 - accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2001752afe0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=100, batch_size=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7751ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4912 - accuracy: 0.8090\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5069 - accuracy: 0.8090\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5182 - accuracy: 0.8090\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5612 - accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5410 - accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4836 - accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5067 - accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4682 - accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4845 - accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5250 - accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5198 - accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4849 - accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5408 - accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4940 - accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5162 - accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5333 - accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4904 - accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5199 - accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4869 - accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4815 - accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4975 - accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4946 - accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4757 - accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4800 - accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5068 - accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5124 - accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5290 - accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5459 - accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5127 - accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5178 - accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5096 - accuracy: 0.8090\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4986 - accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5204 - accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5079 - accuracy: 0.8090\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5228 - accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5203 - accuracy: 0.8090\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4730 - accuracy: 0.8090\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4938 - accuracy: 0.8090\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4916 - accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4751 - accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5557 - accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5165 - accuracy: 0.7978\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4783 - accuracy: 0.7978\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5011 - accuracy: 0.8090\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5009 - accuracy: 0.8090\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4927 - accuracy: 0.8090\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5237 - accuracy: 0.8090\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5138 - accuracy: 0.7978\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5240 - accuracy: 0.7978\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4862 - accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5239 - accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5397 - accuracy: 0.8090\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5158 - accuracy: 0.8090\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5548 - accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5160 - accuracy: 0.8090\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5428 - accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.8090\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5208 - accuracy: 0.8090\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5340 - accuracy: 0.8090\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.8090\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5218 - accuracy: 0.8090\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4919 - accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4897 - accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5153 - accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5519 - accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5090 - accuracy: 0.7978\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5033 - accuracy: 0.7978\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5579 - accuracy: 0.7978\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5052 - accuracy: 0.7978\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5055 - accuracy: 0.7978\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5254 - accuracy: 0.7978\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4973 - accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5049 - accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4923 - accuracy: 0.7978\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5384 - accuracy: 0.7978\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5441 - accuracy: 0.7978\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5201 - accuracy: 0.7978\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5217 - accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.7978\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.7978\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5104 - accuracy: 0.7978\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5131 - accuracy: 0.7978\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5212 - accuracy: 0.7978\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.7978\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5225 - accuracy: 0.7978\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5368 - accuracy: 0.7978\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5097 - accuracy: 0.7978\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5050 - accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5008 - accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5391 - accuracy: 0.7978\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.7978\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4965 - accuracy: 0.7978\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5212 - accuracy: 0.7978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2005df439d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=100, batch_size=32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b495c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5292 - accuracy: 0.7978\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5360 - accuracy: 0.7978\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5176 - accuracy: 0.7978\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5382 - accuracy: 0.7978\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4728 - accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5461 - accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4875 - accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5231 - accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5316 - accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5324 - accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5129 - accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5422 - accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5259 - accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4815 - accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5244 - accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5230 - accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5220 - accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5031 - accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5614 - accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5382 - accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5359 - accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.7978\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5041 - accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5161 - accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5083 - accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5225 - accuracy: 0.7978\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5152 - accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5469 - accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5241 - accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5390 - accuracy: 0.7978\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5138 - accuracy: 0.7978\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5112 - accuracy: 0.7978\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5219 - accuracy: 0.7978\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5195 - accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5284 - accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5023 - accuracy: 0.7978\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5513 - accuracy: 0.7978\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5296 - accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5137 - accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5345 - accuracy: 0.7978\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5319 - accuracy: 0.7978\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5282 - accuracy: 0.7978\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5254 - accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5130 - accuracy: 0.7978\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5363 - accuracy: 0.7978\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4962 - accuracy: 0.7978\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5184 - accuracy: 0.7978\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5206 - accuracy: 0.7978\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5084 - accuracy: 0.7978\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5194 - accuracy: 0.7978\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5211 - accuracy: 0.7978\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5296 - accuracy: 0.7978\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5174 - accuracy: 0.7978\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.7978\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5287 - accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5124 - accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5369 - accuracy: 0.7865\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5342 - accuracy: 0.7865\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5554 - accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5276 - accuracy: 0.7865\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5510 - accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5180 - accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5416 - accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5053 - accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5532 - accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4870 - accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5417 - accuracy: 0.7865\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4983 - accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5562 - accuracy: 0.7753\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5206 - accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4968 - accuracy: 0.7865\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5390 - accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5355 - accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5238 - accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5387 - accuracy: 0.7865\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5430 - accuracy: 0.7753\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5516 - accuracy: 0.7753\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5176 - accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5002 - accuracy: 0.7978\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.7978\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5357 - accuracy: 0.7978\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5190 - accuracy: 0.7978\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5246 - accuracy: 0.7978\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5217 - accuracy: 0.7865\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5521 - accuracy: 0.7865\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5031 - accuracy: 0.7978\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4865 - accuracy: 0.7978\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5194 - accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5295 - accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5254 - accuracy: 0.7978\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5673 - accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5432 - accuracy: 0.7753\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5545 - accuracy: 0.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20008f2f3d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=100, batch_size=32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27de9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8642 - accuracy: 0.5217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8642276525497437, 0.52173912525177]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c4856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
